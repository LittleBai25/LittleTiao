import os
import json
import streamlit as st
import asyncio
from pathlib import Path
from tempfile import NamedTemporaryFile

# Import your existing components
from processor import SimpleProcessor
from llm_processor import LLMProcessor
from config_loader import load_api_config
from qs_usnews_school_dict import qs_school_ranking, usnews_school_ranking

# Import the student tags calculator function
from test_llm import calculate_student_tags, enrich_school_rankings

# Set page configuration
st.set_page_config(
    page_title="ç®€å†å’ŒOfferåˆ†æå·¥å…·",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Function to save uploaded file to a temporary location
def save_uploaded_file(uploaded_file):
    try:
        with NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
            temp_file.write(uploaded_file.getvalue())
            return temp_file.name
    except Exception as e:
        st.error(f"ä¸Šä¼ æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return None

# Create a function to process files and display results
async def process_files(resume_file, offer_files, api_key=None):
    # Create processor instances
    processor = SimpleProcessor()
    
    try:
        llm_processor = LLMProcessor(api_key=api_key)
        st.success("LLMå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
    except ValueError as e:
        st.error(f"LLMå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # Process resume file
    with st.spinner("æ­£åœ¨å¤„ç†ç®€å†..."):
        resume_temp_path = save_uploaded_file(resume_file)
        resume_result = processor.process_resume(resume_temp_path)
        
        if not resume_result["success"]:
            st.error(f"ç®€å†å¤„ç†å¤±è´¥: {resume_result['error']}")
            if resume_temp_path:
                os.unlink(resume_temp_path)
            return
        
        st.success("ç®€å†æ–‡æœ¬æå–æˆåŠŸ")
        st.text_area("ç®€å†æ–‡æœ¬é¢„è§ˆ", resume_result["content"][:1000] + "...", height=200)
    
    # Process offer files
    offer_texts = []
    offer_temp_paths = []
    
    if offer_files:
        with st.spinner("æ­£åœ¨å¤„ç†Offeræ–‡ä»¶..."):
            for i, offer_file in enumerate(offer_files):
                offer_temp_path = save_uploaded_file(offer_file)
                offer_temp_paths.append(offer_temp_path)
                
                offer_result = processor.process_resume(offer_temp_path)  # Using resume method for text extraction
                
                if offer_result["success"]:
                    st.success(f"Offer {i+1} æ–‡æœ¬æå–æˆåŠŸ")
                    with st.expander(f"Offer {i+1} æ–‡æœ¬é¢„è§ˆ"):
                        st.text_area(f"Offer {i+1}", offer_result["content"][:1000] + "...", height=200)
                    offer_texts.append(offer_result["content"])
                else:
                    st.error(f"Offer {i+1} å¤„ç†å¤±è´¥: {offer_result['error']}")
    
    # Use async method to process documents in parallel
    with st.spinner("æ­£åœ¨ä½¿ç”¨LLMåˆ†ææ–‡æ¡£..."):
        start_time = asyncio.get_event_loop().time()
        
        combined_result = await llm_processor.process_documents(
            resume_text=resume_result["content"],
            offer_texts=offer_texts
        )
        
        elapsed = asyncio.get_event_loop().time() - start_time
        st.success(f"LLMåˆ†æå®Œæˆ! æ€»è€—æ—¶: {elapsed:.2f}ç§’")
    
    # Enrich school rankings and add tags
    combined_result = enrich_school_rankings(combined_result)
    tags = calculate_student_tags(combined_result)
    combined_result["tags"] = tags
    
    # Display results
    st.header("åˆ†æç»“æœ", divider="blue")
    
    # Display tags if any
    if tags:
        st.subheader("ğŸ·ï¸ å­¦ç”Ÿæ ‡ç­¾")
        for tag in tags.split("+"):
            st.markdown(f"<span style='background-color: #e6f3ff; padding: 5px 10px; border-radius: 15px; margin-right: 10px;'>{tag}</span>", unsafe_allow_html=True)
    
    # Resume analysis
    st.subheader("ç®€å†åˆ†æ")
    resume_analysis = combined_result["resume_analysis"]
    
    # Display basic info
    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f"**å­¦ç”Ÿ**: {resume_analysis.get('studentName', 'N/A')}")
    
    # Display education info
    education = resume_analysis.get("education", {})
    if education:
        st.markdown("#### æ•™è‚²èƒŒæ™¯")
        edu_cols = st.columns(3)
        with edu_cols[0]:
            st.markdown(f"**å­¦æ ¡**: {education.get('institution', 'N/A')}")
        with edu_cols[1]:
            st.markdown(f"**ä¸“ä¸š**: {education.get('major', 'N/A')}")
        with edu_cols[2]:
            st.markdown(f"**GPA**: {education.get('gpaOriginal', 'N/A')}")
    
    # Display test scores
    test_scores = resume_analysis.get("testScores", [])
    if test_scores:
        st.markdown("#### è€ƒè¯•æˆç»©")
        for score in test_scores:
            st.markdown(f"**{score.get('testName', 'N/A')}**: {score.get('testScore', 'N/A')}")
            if score.get("detailScores"):
                details = score.get("detailScores", {})
                detail_text = ", ".join([f"{k}: {v}" for k, v in details.items()])
                st.markdown(f"*è¯¦ç»†åˆ†æ•°*: {detail_text}")
    
    # Display experiences
    experiences = resume_analysis.get("experiences", [])
    if experiences:
        st.markdown("#### ç»å†")
        for i, exp in enumerate(experiences):
            with st.expander(f"{exp.get('type', 'N/A')} - {exp.get('organization', 'N/A')}"):
                st.markdown(f"**è§’è‰²**: {exp.get('role', 'N/A')}")
                st.markdown(f"**æ—¶é•¿**: {exp.get('duration', 'N/A')}")
                st.markdown(f"**æè¿°**: {exp.get('description', 'N/A')}")
                st.markdown(f"**æˆå°±**: {exp.get('achievement', 'N/A')}")
    
    # Offer analysis
    if combined_result["offer_analyses"]:
        st.subheader("Offeråˆ†æ")
        
        # Create tabs for each offer
        offer_tabs = st.tabs([f"Offer {i+1}" for i in range(len(combined_result["offer_analyses"]))])
        
        for i, (tab, offer_analysis) in enumerate(zip(offer_tabs, combined_result["offer_analyses"])):
            with tab:
                admissions = offer_analysis.get("admissions", [])
                for j, adm in enumerate(admissions):
                    st.markdown(f"#### å½•å– {j+1}")
                    
                    # School and program info
                    cols = st.columns(3)
                    with cols[0]:
                        st.markdown(f"**å­¦æ ¡**: {adm.get('school', 'N/A')}")
                        st.markdown(f"**å›½å®¶**: {adm.get('country', 'N/A')}")
                    with cols[1]:
                        st.markdown(f"**é¡¹ç›®**: {adm.get('program', 'N/A')}")
                        st.markdown(f"**ç±»åˆ«**: {adm.get('majorCategory', 'N/A')}")
                    with cols[2]:
                        st.markdown(f"**å­¦ä½**: {adm.get('degreeType', 'N/A')}")
                        st.markdown(f"**å…¥å­¦å­£èŠ‚**: {adm.get('enrollmentSeason', 'N/A')}")
                    
                    # Ranking info
                    rank_cols = st.columns(3)
                    with rank_cols[0]:
                        st.markdown(f"**æ’åç±»å‹**: {adm.get('rankingType', 'N/A')}")
                    with rank_cols[1]:
                        st.markdown(f"**æ’å**: {adm.get('rankingValue', 'N/A')}")
                    with rank_cols[2]:
                        st.markdown(f"**æ’åå±‚çº§**: {adm.get('rankingTier', 'N/A')}")
                    
                    # Scholarship info
                    if adm.get("hasScholarship"):
                        st.markdown("ğŸ’° **è·å¾—å¥–å­¦é‡‘**")
                        st.markdown(f"**é‡‘é¢**: {adm.get('scholarshipAmount', 'N/A')}")
                        if adm.get("scholarshipNote"):
                            st.markdown(f"**å¤‡æ³¨**: {adm.get('scholarshipNote')}")
    
    # Option to download results as JSON
    st.download_button(
        label="ä¸‹è½½å®Œæ•´åˆ†æç»“æœ (JSON)",
        data=json.dumps(combined_result, ensure_ascii=False, indent=2),
        file_name="åˆ†æç»“æœ.json",
        mime="application/json"
    )
    
    # Clean up temporary files
    if resume_temp_path:
        os.unlink(resume_temp_path)
    for path in offer_temp_paths:
        os.unlink(path)

# Main app
def main():
    st.title("ğŸ“ ç®€å†å’ŒOfferåˆ†æå·¥å…·")
    
    # Sidebar for API configuration
    st.sidebar.header("APIè®¾ç½®")
    
    # Try to load API key from config
    config = load_api_config()
    default_api_key = config.get("OPENAI_API_KEY", "")
    
    # API key input
    api_key = st.sidebar.text_input(
        "OpenAI APIå¯†é’¥", 
        value=default_api_key,
        type="password",
        help="è¾“å…¥ä½ çš„OpenAI APIå¯†é’¥ï¼Œç”¨äºLLMåˆ†æ"
    )
    
    # About section in sidebar
    st.sidebar.markdown("---")
    st.sidebar.markdown("### å…³äº")
    st.sidebar.info(
        "è¿™ä¸ªåº”ç”¨å¯ä»¥åˆ†æç®€å†å’ŒOfferæ–‡ä»¶ï¼Œæå–å…³é”®ä¿¡æ¯ï¼Œ"
        "å¹¶ä½¿ç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æã€‚"
    )

    # File upload section
    st.header("ä¸Šä¼ æ–‡ä»¶", divider="gray")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Resume upload
        resume_file = st.file_uploader("ä¸Šä¼ ç®€å† (PDFæ ¼å¼)", type=["pdf"], help="è¯·ä¸Šä¼ ç®€å†PDFæ–‡ä»¶")
    
    with col2:
        # Offer upload
        offer_files = st.file_uploader("ä¸Šä¼ Offeræ–‡ä»¶ (PDFæ ¼å¼ï¼Œå¯å¤šé€‰)", type=["pdf"], accept_multiple_files=True, help="å¯ä»¥ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ªOffer PDFæ–‡ä»¶")
    
    # Process button
    if st.button("å¼€å§‹åˆ†æ", disabled=not resume_file):
        if not api_key:
            st.error("è¯·æä¾›OpenAI APIå¯†é’¥æ‰èƒ½å¼€å§‹åˆ†æ")
        elif not resume_file:
            st.error("è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ªç®€å†æ–‡ä»¶")
        else:
            # Use asyncio to run the async processing function
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                loop.run_until_complete(process_files(resume_file, offer_files, api_key))
            finally:
                loop.close()

if __name__ == "__main__":
    main()
