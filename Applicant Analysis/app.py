import streamlit as st
import os
from PIL import Image
import io
from datetime import datetime
import uuid

# Import custom modules
from agents.transcript_analyzer import TranscriptAnalyzer
from agents.competitiveness_analyst import CompetitivenessAnalyst
from agents.consulting_assistant import ConsultingAssistant
from agents.serper_client import SerperClient
from config.prompts import load_prompts, save_prompts

# å¯¼å…¥LangSmithè¿½è¸ªåŠŸèƒ½
from langsmith import Client
from langsmith.run_helpers import traceable

# Set page configuration
st.set_page_config(
    page_title="Applicant Analysis Tool",
    page_icon="ğŸ“",
    layout="wide"
)

# Initialize LangSmith client
def init_langsmith():
    """Initialize LangSmith client from secrets."""
    try:
        langsmith_api_key = st.secrets.get("LANGSMITH_API_KEY", "")
        langsmith_project = st.secrets.get("LANGSMITH_PROJECT", "applicant-analysis-tool")
        
        if langsmith_api_key:
            os.environ["LANGCHAIN_API_KEY"] = langsmith_api_key
            os.environ["LANGCHAIN_PROJECT"] = langsmith_project
            os.environ["LANGCHAIN_TRACING_V2"] = "true"
            return True
        return False
    except Exception as e:
        st.error(f"Error initializing LangSmith: {str(e)}")
        return False

# åˆå§‹åŒ–LangSmith
langsmith_enabled = init_langsmith()

# Initialize session state
if "competitiveness_report" not in st.session_state:
    st.session_state.competitiveness_report = None
if "project_recommendations" not in st.session_state:
    st.session_state.project_recommendations = None
if "transcript_content" not in st.session_state:
    st.session_state.transcript_content = None
if "serper_initialized" not in st.session_state:
    st.session_state.serper_initialized = False
if "analyst_model" not in st.session_state:
    st.session_state.analyst_model = "qwen/qwen-max"
if "consultant_model" not in st.session_state:
    st.session_state.consultant_model = "qwen/qwen-max"

# Check if necessary API keys are set
def check_api_keys():
    """Check if the necessary API keys are set in Streamlit secrets."""
    api_keys = {
        "OPENROUTER_API_KEY": st.secrets.get("OPENROUTER_API_KEY", None),
        "SERPER_API_KEY": st.secrets.get("SERPER_API_KEY", None),
        "SMITHERY_API_KEY": st.secrets.get("SMITHERY_API_KEY", None),
        "LANGSMITH_API_KEY": st.secrets.get("LANGSMITH_API_KEY", None)
    }
    
    return {k: bool(v) for k, v in api_keys.items()}

# Asynchronously initialize the Serper client
async def init_serper():
    """Initialize the Serper client asynchronously."""
    serper_client = SerperClient()
    result = await serper_client.initialize()
    st.session_state.serper_initialized = result
    return result

# æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
SUPPORTED_MODELS = [
    "qwen/qwen-max",
    "qwen/qwen3-32b:free",
    "deepseek/deepseek-chat-v3-0324:free",
    "anthropic/claude-3.7-sonnet",
    "openai/gpt-4.1"
]

# ä½¿ç”¨LangSmithè¿½è¸ªåˆ†æå¸ˆç”ŸæˆæŠ¥å‘Šçš„å‡½æ•°
@traceable(run_type="chain", name="CompetitivenessAnalysis")
def generate_competitiveness_report(analyst, university, major, predicted_degree, transcript_content):
    """è¿½è¸ªç«äº‰åŠ›åˆ†ææŠ¥å‘Šçš„ç”Ÿæˆè¿‡ç¨‹"""
    return analyst.generate_report(
        university=university,
        major=major,
        predicted_degree=predicted_degree,
        transcript_content=transcript_content
    )

# ä½¿ç”¨LangSmithè¿½è¸ªå’¨è¯¢åŠ©æ‰‹æ¨èé¡¹ç›®çš„å‡½æ•°
@traceable(run_type="chain", name="ProgramRecommendations")
def generate_program_recommendations(consultant, competitiveness_report):
    """è¿½è¸ªé¡¹ç›®æ¨èçš„ç”Ÿæˆè¿‡ç¨‹"""
    return consultant.recommend_projects(
        competitiveness_report=competitiveness_report
    )

# Main function
def main():
    # Create tabs
    tab1, tab2, tab3 = st.tabs(["Competitiveness Analysis", "Prompt Debugging", "System Status"])
    
    with tab1:
        st.title("Applicant Competitiveness Analysis Tool")
        
        # Form for user inputs
        with st.form("input_form"):
            # University selection (currently only one option)
            university = st.selectbox(
                "Select University",
                ["Xi'an Jiaotong-Liverpool University"],
                index=0
            )
            
            # Major input
            major = st.text_input("Enter Your Major")
            
            # Predicted degree classification
            predicted_degree = st.selectbox(
                "Predicted Degree Classification",
                ["First Class", "Upper Second Class", "Lower Second Class", "Third Class"]
            )
            
            # Transcript upload (only image formats)
            transcript_file = st.file_uploader(
                "Upload Your Transcript (Image format only)",
                type=["jpg", "jpeg", "png"]
            )
            
            # Submit button
            submitted = st.form_submit_button("Submit")
        
        # Process the form submission
        if submitted and transcript_file is not None and major:
            # ä»session stateè·å–æ¨¡å‹é€‰æ‹©
            analyst_model = st.session_state.analyst_model
            consultant_model = st.session_state.consultant_model
            
            # ç”Ÿæˆä¸€ä¸ªä¼šè¯IDï¼Œç”¨äºLangSmithè¿½è¸ª
            session_id = str(uuid.uuid4())
            
            # First step: Process the transcript with TranscriptAnalyzer
            with st.spinner("Analyzing transcript with Qwen 2.5 VL via OpenRouter..."):
                # Save and display the uploaded image
                image = Image.open(transcript_file)
                st.image(image, caption="Uploaded Transcript", use_column_width=True)
                
                # Process the transcript with AI
                transcript_analyzer = TranscriptAnalyzer()
                transcript_content = transcript_analyzer.extract_transcript_data(image)
                st.session_state.transcript_content = transcript_content
                
                # Display the extracted transcript data
                st.subheader("Extracted Transcript Data")
                st.text_area("Transcript Content", transcript_content, height=200, disabled=True)
            
            # Second step: Generate competitiveness report
            with st.spinner(f"Generating competitiveness report with {analyst_model} via OpenRouter..."):
                analyst = CompetitivenessAnalyst(model_name=analyst_model)
                
                # ä½¿ç”¨LangSmithè¿½è¸ªå‡½æ•°åŒ…è£…åŸå§‹è°ƒç”¨
                if langsmith_enabled:
                    # ä½¿ç”¨è£…é¥°å™¨è¿½è¸ªçš„å‡½æ•°
                    with st.status("LangSmith: Tracking competitiveness analysis..."):
                        st.session_state.competitiveness_report = generate_competitiveness_report(
                            analyst,
                            university=university,
                            major=major,
                            predicted_degree=predicted_degree,
                            transcript_content=transcript_content
                        )
                else:
                    # ç›´æ¥è°ƒç”¨å‡½æ•°
                    st.session_state.competitiveness_report = analyst.generate_report(
                        university=university,
                        major=major,
                        predicted_degree=predicted_degree,
                        transcript_content=transcript_content
                    )
                
                # Display competitiveness report
                st.subheader("Competitiveness Analysis Report")
                st.markdown(st.session_state.competitiveness_report)
            
            # Third step: Generate program recommendations
            with st.spinner(f"Generating program recommendations with {consultant_model} via OpenRouter..."):
                consultant = ConsultingAssistant(model_name=consultant_model)
                
                # ä½¿ç”¨LangSmithè¿½è¸ªå‡½æ•°åŒ…è£…åŸå§‹è°ƒç”¨
                if langsmith_enabled:
                    # ä½¿ç”¨è£…é¥°å™¨è¿½è¸ªçš„å‡½æ•°
                    with st.status("LangSmith: Tracking program recommendations..."):
                        st.session_state.project_recommendations = generate_program_recommendations(
                            consultant,
                            competitiveness_report=st.session_state.competitiveness_report
                        )
                else:
                    # ç›´æ¥è°ƒç”¨å‡½æ•°
                    st.session_state.project_recommendations = consultant.recommend_projects(
                        competitiveness_report=st.session_state.competitiveness_report
                    )
                
                # Display program recommendations
                st.subheader("UCL Program Recommendations")
                st.markdown(st.session_state.project_recommendations)
        
        # If not submitted but we have stored results, display them
        elif not submitted:
            if st.session_state.transcript_content:
                st.subheader("Extracted Transcript Data")
                st.text_area("Transcript Content", st.session_state.transcript_content, height=200, disabled=True)
            
            if st.session_state.competitiveness_report:
                st.subheader("Competitiveness Analysis Report")
                st.markdown(st.session_state.competitiveness_report)
            
            if st.session_state.project_recommendations:
                st.subheader("UCL Program Recommendations")
                st.markdown(st.session_state.project_recommendations)
    
    with tab2:
        st.title("AI Model & Prompt Configuration")
        
        # æ·»åŠ æ¨¡å‹é€‰æ‹©åˆ°æç¤ºè¯è°ƒè¯•é¡µé¢é¡¶éƒ¨
        st.subheader("Model Selection")
        col1, col2 = st.columns(2)
        
        with col1:
            # Model selection for CompetitivenessAnalyst
            analyst_model = st.selectbox(
                "Select Model for Competitiveness Analysis",
                SUPPORTED_MODELS,
                index=SUPPORTED_MODELS.index(st.session_state.analyst_model) if st.session_state.analyst_model in SUPPORTED_MODELS else 0,
                key="analyst_model_debug"
            )
            st.session_state.analyst_model = analyst_model
            
        with col2:
            # Model selection for ConsultingAssistant
            consultant_model = st.selectbox(
                "Select Model for Program Recommendations",
                SUPPORTED_MODELS,
                index=SUPPORTED_MODELS.index(st.session_state.consultant_model) if st.session_state.consultant_model in SUPPORTED_MODELS else 0,
                key="consultant_model_debug"
            )
            st.session_state.consultant_model = consultant_model
        
        # æ·»åŠ æ¨¡å‹é€‰æ‹©è¯´æ˜
        st.info("è¿™äº›æ¨¡å‹è®¾ç½®å°†åº”ç”¨äºç«äº‰åŠ›åˆ†æå’Œé¡¹ç›®æ¨èã€‚æ‚¨çš„é€‰æ‹©å°†ä¿å­˜åœ¨ä¼šè¯ä¸­ã€‚")
        
        st.markdown("---")
        
        # Load current prompts
        prompts = load_prompts()
        
        st.subheader("Transcript Analyzer Settings")
        st.markdown("""
        The Transcript Analyzer uses Qwen 2.5 VL (qwen/qwen2.5-vl-72b-instruct) via OpenRouter.
        
        This model is specifically tuned for visual document analysis and transcript data extraction.
        """)
        
        st.subheader("Competitiveness Analyst (Agent 1)")
        
        analyst_role = st.text_area("Role Description", prompts["analyst"]["role"], height=200)
        analyst_task = st.text_area("Task Description", prompts["analyst"]["task"], height=200)
        analyst_output = st.text_area("Output Format", prompts["analyst"]["output"], height=200)
        
        st.subheader("Consulting Assistant (Agent 2)")
        
        consultant_role = st.text_area("Role Description", prompts["consultant"]["role"], height=200)
        consultant_task = st.text_area("Task Description", prompts["consultant"]["task"], height=200)
        consultant_output = st.text_area("Output Format", prompts["consultant"]["output"], height=200)
        
        # ä¿å­˜æŒ‰é’®ï¼Œä¸ä½¿ç”¨è¡¨å•
        if st.button("Save Prompts"):
            # Update prompts dictionary
            prompts["analyst"]["role"] = analyst_role
            prompts["analyst"]["task"] = analyst_task
            prompts["analyst"]["output"] = analyst_output
            
            prompts["consultant"]["role"] = consultant_role
            prompts["consultant"]["task"] = consultant_task
            prompts["consultant"]["output"] = consultant_output
            
            # Save updated prompts
            save_prompts(prompts)
            st.success("æç¤ºè¯å·²æˆåŠŸä¿å­˜ï¼")

    with tab3:
        st.title("System Status")
        
        # Check API keys
        api_key_status = check_api_keys()
        
        st.subheader("API Keys")
        
        # Display API key status as a table
        status_data = [
            {"API Key": key, "Status": "âœ… å·²è®¾ç½®" if status else "âŒ æœªè®¾ç½®"} 
            for key, status in api_key_status.items()
        ]
        
        st.table(status_data)
        
        # LangSmith çŠ¶æ€
        st.subheader("LangSmith Monitoring")
        if langsmith_enabled:
            st.success("âœ… LangSmith ç›‘æ§å·²å¯ç”¨ï¼Œä¸¤ä¸ªä¸»è¦AIä»£ç†çš„è¾“å…¥å’Œè¾“å‡ºå°†è¢«è¿½è¸ª")
            st.info(f"Project: {os.environ.get('LANGCHAIN_PROJECT', 'N/A')}")
            
            # LangSmith è¯´æ˜
            st.markdown("""
            **LangSmithç›‘æ§åŠŸèƒ½ï¼š**
            - è¿½è¸ªç«äº‰åŠ›åˆ†æå’Œé¡¹ç›®æ¨èçš„å®Œæ•´è¯·æ±‚å’Œå“åº”
            - è®°å½•æ¯ä¸ªä»£ç†çš„è¾“å…¥å‚æ•°å’Œè¾“å‡ºç»“æœ
            - æ”¯æŒåœ¨LangSmithç•Œé¢ä¸Šåˆ†æå’Œä¼˜åŒ–æç¤ºè¯
            - ç›‘æ§æ¨¡å‹æ€§èƒ½å’Œå»¶è¿Ÿ
            """)
        else:
            st.warning("âš ï¸ LangSmith ç›‘æ§æœªå¯ç”¨ã€‚è¯·åœ¨secretsä¸­è®¾ç½® LANGSMITH_API_KEY ä»¥å¯ç”¨æ­¤åŠŸèƒ½")
            
            # è®¾ç½®è¯´æ˜
            st.markdown("""
            **è®¾ç½®LangSmithï¼š**
            1. è·å–LangSmith APIå¯†é’¥: https://smith.langchain.com/
            2. åœ¨`.streamlit/secrets.toml`ä¸­æ·»åŠ :
                ```
                LANGSMITH_API_KEY = "your_api_key_here"
                LANGSMITH_PROJECT = "applicant-analysis-tool"  # å¯é€‰é¡¹
                ```
            """)
        
        # Serper MCP server status
        st.subheader("Serper MCP Server")
        
        # åˆå§‹åŒ–Serperå®¢æˆ·ç«¯æŒ‰é’®ï¼Œä¸ä½¿ç”¨è¡¨å•
        if not st.session_state.serper_initialized:
            if st.button("åˆå§‹åŒ– Serper å®¢æˆ·ç«¯"):
                with st.spinner("æ­£åœ¨åˆå§‹åŒ– Serper å®¢æˆ·ç«¯..."):
                    import asyncio
                    asyncio.run(init_serper())
        
        # Display Serper client status
        if st.session_state.serper_initialized:
            st.success("âœ… Serper å®¢æˆ·ç«¯å·²æˆåŠŸåˆå§‹åŒ–")
        else:
            st.warning("âš ï¸ Serper å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ã€‚ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®è¿›è¡Œåˆå§‹åŒ–ã€‚")
        
        # Add some help text
        st.markdown("""
        ### API å¯†é’¥é…ç½®
        
        æœ¬åº”ç”¨ä½¿ç”¨ Streamlit secrets å­˜å‚¨ API å¯†é’¥ã€‚é…ç½® API å¯†é’¥çš„æ­¥éª¤ï¼š
        
        1. åˆ›å»º `.streamlit/secrets.toml` æ–‡ä»¶å¹¶æ·»åŠ æ‚¨çš„ API å¯†é’¥ï¼š
           ```toml
           # OpenRouter API (ç”¨äºè®¿é—®æ‰€æœ‰LLMæ¨¡å‹ï¼ŒåŒ…æ‹¬è§†è§‰æ¨¡å‹)
           OPENROUTER_API_KEY = "your_openrouter_api_key"
           
           # Serper Webæœç´¢ API (ç”¨äºé¡¹ç›®æ¨è)
           SERPER_API_KEY = "your_serper_api_key"
           SMITHERY_API_KEY = "your_smithery_api_key"
           
           # LangSmithç›‘æ§ API (ç”¨äºè¿½è¸ªAIä»£ç†)
           LANGSMITH_API_KEY = "your_langsmith_api_key"
           LANGSMITH_PROJECT = "applicant-analysis-tool"  # å¯é€‰é¡¹
           ```
        
        2. å¯¹äº Streamlit Cloud éƒ¨ç½²ï¼Œåœ¨ Streamlit Cloud æ§åˆ¶é¢æ¿ä¸­æ·»åŠ è¿™äº›å¯†é’¥
        
        ### å¸¸è§é—®é¢˜æ’æŸ¥
        
        å¦‚æœé‡åˆ°é—®é¢˜ï¼š
        
        1. ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„ API å¯†é’¥éƒ½å·²åœ¨ Streamlit secrets ä¸­è®¾ç½®
        2. æ£€æŸ¥æ§åˆ¶å°æ˜¯å¦æœ‰é”™è¯¯æ¶ˆæ¯
        3. ç¡®ä¿æ‚¨æœ‰æœ‰æ•ˆçš„äº’è”ç½‘è¿æ¥ï¼Œä»¥ä¾¿è¿›è¡Œ Web æœç´¢åŠŸèƒ½
        """)

if __name__ == "__main__":
    main() 