import streamlit as st
import os
from PIL import Image
import io
import pandas as pd
import base64
from dotenv import load_dotenv
import requests
import json
from langchain.agents import AgentExecutor, create_react_agent
from langchain_core.tools import Tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langsmith import Client
from langsmith.run_trees import RunTree
import tempfile
import streamlit.components.v1 as components

# Load environment variables
load_dotenv()

# Page configuration
st.set_page_config(
    page_title="èŒä¸šè§„åˆ’åŠ©ç†",
    page_icon="ğŸš€",
    layout="wide"
)

# Available models
AVAILABLE_MODELS = {
    "qwen/qwen3-32b:free": "Qwen 3 32B",
    "deepseek/deepseek-chat-v3-0324:free": "DeepSeek Chat v3",
    "qwen/qwen-max": "Qwen Max"
}

# Session state initialization
if 'user_inputs' not in st.session_state:
    st.session_state.user_inputs = {
        "university": "",
        "major": "",
        "target_industry": "",
        "target_position": "",
        "transcript_text": ""
    }

if 'career_agent_settings' not in st.session_state:
    st.session_state.career_agent_settings = {
        "role": "æ‚¨æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„èŒä¸šè§„åˆ’é¡¾é—®ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„è¡Œä¸šçŸ¥è¯†å’Œæ´å¯ŸåŠ›ã€‚",
        "task": "åŸºäºç”¨æˆ·æä¾›çš„å­¦æœ¯èƒŒæ™¯ã€ä¸“ä¸šã€æ„å‘è¡Œä¸šå’ŒèŒä½ï¼Œåˆ†æå…¶èŒä¸šå‘å±•è·¯å¾„ï¼Œæä¾›å…·ä½“å¯è¡Œçš„å»ºè®®ã€‚",
        "output_format": "è¯·æä¾›ä¸€ä»½ç»“æ„åŒ–çš„èŒä¸šè§„åˆ’åˆ†æï¼ŒåŒ…æ‹¬ï¼š\n1. èƒŒæ™¯åˆ†æ\n2. èŒä¸šè·¯å¾„å»ºè®®\n3. æŠ€èƒ½æå‡æ–¹å‘\n4. è¡Œä¸šå‰æ™¯\n5. çŸ­æœŸå’Œé•¿æœŸç›®æ ‡",
        "model": "qwen/qwen3-32b:free"
    }

if 'submission_agent_settings' not in st.session_state:
    st.session_state.submission_agent_settings = {
        "role": "æ‚¨æ˜¯ä¸€ä½ä¸“ä¸šçš„èŒä¸šè§„åˆ’æŠ¥å‘Šç¼–è¾‘ï¼Œæ“…é•¿æ•´åˆä¿¡æ¯å¹¶åˆ¶ä½œç¾è§‚çš„æŠ¥å‘Šã€‚",
        "task": "åŸºäºèŒä¸šè§„åˆ’è‰ç¨¿ï¼Œè¡¥å……ç›¸å…³è¡Œä¸šæ•°æ®å’Œä¿¡æ¯ï¼Œåˆ¶ä½œä¸€ä»½åŒ…å«æ–‡å­—è¯´æ˜å’Œå¯è§†åŒ–å›¾è¡¨çš„å®Œæ•´æŠ¥å‘Šã€‚",
        "output_format": "è¯·æä¾›ä¸€ä»½ä¸“ä¸šçš„èŒä¸šè§„åˆ’æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š\n1. æ‰§è¡Œæ‘˜è¦\n2. è¯¦ç»†åˆ†æ\n3. æ•°æ®æ”¯æŒçš„å›¾è¡¨\n4. è¡ŒåŠ¨è®¡åˆ’\n5. èµ„æºæ¨è",
        "model": "deepseek/deepseek-chat-v3-0324:free"
    }

if 'draft_report' not in st.session_state:
    st.session_state.draft_report = ""

if 'final_report' not in st.session_state:
    st.session_state.final_report = ""

if 'api_status' not in st.session_state:
    st.session_state.api_status = {
        "openrouter": False,
        "qwen": False,
        "langsmith": False
    }

# Simulated knowledge database
class KnowledgeDatabase:
    def __init__(self):
        # This would be replaced with an actual database connection in production
        self.data = {
            "industries": {
                "IT/äº’è”ç½‘": {
                    "positions": [
                        {
                            "name": "è½¯ä»¶å·¥ç¨‹å¸ˆ",
                            "skills": "Python, Java, JavaScript, æ•°æ®ç»“æ„, ç®—æ³•",
                            "education": "è®¡ç®—æœºç§‘å­¦/è½¯ä»¶å·¥ç¨‹ç›¸å…³æœ¬ç§‘åŠä»¥ä¸Š",
                            "salary": "15K-30K",
                            "prospects": "è¡Œä¸šéœ€æ±‚æŒç»­å¢é•¿ï¼Œå‘å±•ç©ºé—´å¹¿é˜”"
                        },
                        {
                            "name": "å‰ç«¯å¼€å‘",
                            "skills": "HTML, CSS, JavaScript, React/Vue/Angular, TypeScript",
                            "education": "è®¡ç®—æœºç›¸å…³ä¸“ä¸šæœ¬ç§‘åŠä»¥ä¸Š",
                            "salary": "12K-25K",
                            "prospects": "éšç€äº’è”ç½‘äº§å“ä¸æ–­å‘å±•ï¼Œå‰ç«¯å¼€å‘äººæ‰éœ€æ±‚æ—ºç››"
                        },
                        {
                            "name": "æ•°æ®åˆ†æå¸ˆ",
                            "skills": "SQL, Python, R, Excel, æ•°æ®å¯è§†åŒ–, ç»Ÿè®¡å­¦åŸºç¡€",
                            "education": "ç»Ÿè®¡å­¦/æ•°å­¦/è®¡ç®—æœºç›¸å…³ä¸“ä¸šæœ¬ç§‘åŠä»¥ä¸Š",
                            "salary": "15K-30K",
                            "prospects": "å¤§æ•°æ®æ—¶ä»£ï¼Œæ•°æ®åˆ†æäººæ‰ç¨€ç¼ºï¼Œå‘å±•å‰æ™¯è‰¯å¥½"
                        }
                    ],
                    "overview": "IT/äº’è”ç½‘è¡Œä¸šæŠ€æœ¯æ›´æ–°å¿«ï¼Œç«äº‰æ¿€çƒˆï¼Œä½†è–ªèµ„æ°´å¹³å’Œå‘å±•ç©ºé—´è¾ƒå¤§"
                },
                "é‡‘è": {
                    "positions": [
                        {
                            "name": "æŠ•èµ„åˆ†æå¸ˆ",
                            "skills": "è´¢åŠ¡åˆ†æ, ä¼°å€¼æ¨¡å‹, Excel, é‡‘èå¸‚åœºçŸ¥è¯†",
                            "education": "é‡‘è/ç»æµ/ä¼šè®¡ç›¸å…³ä¸“ä¸šæœ¬ç§‘åŠä»¥ä¸Š",
                            "salary": "12K-30K",
                            "prospects": "é‡‘èè¡Œä¸šç¨³å®šï¼Œæ™‹å‡è·¯å¾„æ¸…æ™°"
                        },
                        {
                            "name": "é£é™©æ§åˆ¶",
                            "skills": "é£é™©è¯„ä¼°, æ•°æ®åˆ†æ, æ³•è§„çŸ¥è¯†, é‡‘èå·¥å…·",
                            "education": "é‡‘è/æ•°å­¦/ç»Ÿè®¡ç›¸å…³ä¸“ä¸šæœ¬ç§‘åŠä»¥ä¸Š",
                            "salary": "15K-35K",
                            "prospects": "é£æ§äººæ‰éœ€æ±‚ç¨³å®šï¼ŒèŒä¸šå‘å±•å‰æ™¯è‰¯å¥½"
                        }
                    ],
                    "overview": "é‡‘èè¡Œä¸šç›¸å¯¹ç¨³å®šï¼Œæ³¨é‡ä¸“ä¸šæ€§å’Œåˆè§„æ€§ï¼ŒèŒä¸šå‘å±•ä½“ç³»è¾ƒä¸ºæˆç†Ÿ"
                }
            },
            "majors": {
                "è®¡ç®—æœºç§‘å­¦": {
                    "suitable_industries": ["IT/äº’è”ç½‘", "é‡‘è", "æ•™è‚²"],
                    "suitable_positions": ["è½¯ä»¶å·¥ç¨‹å¸ˆ", "æ•°æ®åˆ†æå¸ˆ", "ITé¡¾é—®"],
                    "core_skills": "ç¼–ç¨‹è¯­è¨€, æ•°æ®ç»“æ„, ç®—æ³•, æ•°æ®åº“, ç½‘ç»œåŸºç¡€",
                    "career_paths": "å¯ä»å¼€å‘å·¥ç¨‹å¸ˆå‘å±•ä¸ºæ¶æ„å¸ˆã€æŠ€æœ¯ç»ç†æˆ–äº§å“ç»ç†"
                },
                "é‡‘èå­¦": {
                    "suitable_industries": ["é‡‘è", "å’¨è¯¢", "ä¼ä¸šè´¢åŠ¡"],
                    "suitable_positions": ["æŠ•èµ„åˆ†æå¸ˆ", "é£é™©æ§åˆ¶", "è´¢åŠ¡é¡¾é—®"],
                    "core_skills": "è´¢åŠ¡åˆ†æ, é‡‘èå¸‚åœº, é£é™©ç®¡ç†, æŠ•èµ„ç†è®º",
                    "career_paths": "å¯ä»åˆ†æå¸ˆå‘å±•ä¸ºæŠ•èµ„ç»ç†ã€é£æ§ç»ç†æˆ–è´¢åŠ¡æ€»ç›‘"
                }
            }
        }
    
    def query(self, query_type, query_value):
        """
        Query the database with different query types
        query_type can be: 'industry', 'position', 'major'
        """
        if query_type == 'industry' and query_value in self.data['industries']:
            return self.data['industries'][query_value]
        elif query_type == 'major' and query_value in self.data['majors']:
            return self.data['majors'][query_value]
        elif query_type == 'position':
            # Search for position across all industries
            for industry, industry_data in self.data['industries'].items():
                for position in industry_data['positions']:
                    if position['name'] == query_value:
                        return position
            return None
        else:
            return None

# Initialize knowledge database
knowledge_db = KnowledgeDatabase()

# Initialize LangSmith client if enabled
def init_langsmith():
    try:
        langsmith_api_key = st.secrets.get("LANGSMITH_API_KEY")
        langsmith_project = st.secrets.get("LANGSMITH_PROJECT", "career-planner")
        os.environ["LANGSMITH_API_KEY"] = langsmith_api_key
        os.environ["LANGCHAIN_PROJECT"] = langsmith_project
        return Client(api_key=langsmith_api_key)
    except Exception as e:
        st.error(f"LangSmith initialization error: {str(e)}")
        return None

# Function to call OpenRouter for API requests
def call_openrouter(messages, model, temperature=0.7):
    try:
        api_key = st.secrets.get("OPENROUTER_API_KEY")
        if not api_key:
            return "é”™è¯¯ï¼šæœªè®¾ç½®OpenRouter APIå¯†é’¥"
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://career-planner.streamlit.app"  # Replace with your actual domain
        }
        
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature
        }
        
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=payload
        )
        
        result = response.json()
        if "choices" in result and len(result["choices"]) > 0:
            return result["choices"][0]["message"]["content"]
        else:
            return f"è¯·æ±‚å¤±è´¥: {str(result)}"
    except Exception as e:
        return f"è¯·æ±‚è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"

# Function to call Qwen VL model for transcript analysis
def analyze_transcript_with_qwen(image_bytes):
    try:
        # For Qwen VL we'll continue using Qwen's API directly as it has multimodal capabilities
        api_key = st.secrets.get("QWEN_API_KEY")
        if not api_key:
            return "é”™è¯¯ï¼šæœªè®¾ç½®Qwen APIå¯†é’¥"
        
        # Convert image to base64
        base64_image = base64.b64encode(image_bytes).decode('utf-8')
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": "qwen/qwen2.5-vl-72b-instruct",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "è¿™æ˜¯ä¸€ä»½æˆç»©å•ï¼Œè¯·è¯†åˆ«å¹¶æå–å‡ºæ‰€æœ‰è¯¾ç¨‹åç§°ã€å­¦åˆ†å’Œæˆç»©ä¿¡æ¯ï¼Œæ•´ç†æˆè¡¨æ ¼å½¢å¼ã€‚"},
                        {"type": "image", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                    ]
                }
            ]
        }
        
        response = requests.post("https://api.qwen.ai/v1/chat/completions", headers=headers, json=payload)
        result = response.json()
        
        if "choices" in result and len(result["choices"]) > 0:
            return result["choices"][0]["message"]["content"]
        else:
            return f"åˆ†æå¤±è´¥: {str(result)}"
    except Exception as e:
        return f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"

# Function to render Mermaid diagrams
def render_mermaid(mermaid_code):
    html = f"""
    <div class="mermaid">
    {mermaid_code}
    </div>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({{ startOnLoad: true }});
    </script>
    """
    components.html(html, height=500)

# Function to check API status
def check_api_status():
    # Check OpenRouter API
    try:
        openrouter_key = st.secrets.get("OPENROUTER_API_KEY")
        if openrouter_key:
            headers = {
                "Authorization": f"Bearer {openrouter_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://career-planner.streamlit.app"
            }
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json={
                    "model": "qwen/qwen3-32b:free",  # Use one of our allowed models
                    "messages": [{"role": "user", "content": "Hello"}],
                    "max_tokens": 5
                }
            )
            st.session_state.api_status["openrouter"] = response.status_code == 200
        else:
            st.session_state.api_status["openrouter"] = False
    except:
        st.session_state.api_status["openrouter"] = False
    
    # Check Qwen API
    try:
        qwen_key = st.secrets.get("QWEN_API_KEY")
        if qwen_key:
            headers = {
                "Authorization": f"Bearer {qwen_key}",
                "Content-Type": "application/json"
            }
            response = requests.post(
                "https://api.qwen.ai/v1/chat/completions",
                headers=headers,
                json={
                    "model": "qwen/qwen2.5-vl-72b-instruct",
                    "messages": [{"role": "user", "content": "Hello"}]
                }
            )
            st.session_state.api_status["qwen"] = response.status_code == 200
        else:
            st.session_state.api_status["qwen"] = False
    except:
        st.session_state.api_status["qwen"] = False
    
    # Check LangSmith status
    try:
        langsmith_key = st.secrets.get("LANGSMITH_API_KEY")
        if langsmith_key:
            client = Client(api_key=langsmith_key)
            # Just try to access the API
            _ = client.list_projects(limit=1)
            st.session_state.api_status["langsmith"] = True
        else:
            st.session_state.api_status["langsmith"] = False
    except:
        st.session_state.api_status["langsmith"] = False

# Function to query knowledge database
def query_knowledge_db(user_inputs):
    results = []
    
    # Query by industry
    if user_inputs['target_industry']:
        industry_data = knowledge_db.query('industry', user_inputs['target_industry'])
        if industry_data:
            results.append(f"è¡Œä¸šæ¦‚è§ˆ - {user_inputs['target_industry']}:\n{industry_data['overview']}")
            
            # If position is specified, find specific position data
            if user_inputs['target_position']:
                for position in industry_data['positions']:
                    if position['name'] == user_inputs['target_position']:
                        results.append(f"å²—ä½è¯¦æƒ… - {position['name']}:\n"
                                      f"æ‰€éœ€æŠ€èƒ½: {position['skills']}\n"
                                      f"å­¦å†è¦æ±‚: {position['education']}\n"
                                      f"è–ªèµ„èŒƒå›´: {position['salary']}\n"
                                      f"å‘å±•å‰æ™¯: {position['prospects']}")
                        break
            else:
                # List all positions in this industry
                results.append(f"{user_inputs['target_industry']}è¡Œä¸šçƒ­é—¨å²—ä½:")
                for position in industry_data['positions']:
                    results.append(f"- {position['name']}: {position['prospects']}")
    
    # Query by major
    if user_inputs['major']:
        major_data = knowledge_db.query('major', user_inputs['major'])
        if major_data:
            results.append(f"ä¸“ä¸šå°±ä¸šæ–¹å‘ - {user_inputs['major']}:\n"
                          f"é€‚åˆè¡Œä¸š: {', '.join(major_data['suitable_industries'])}\n"
                          f"é€‚åˆå²—ä½: {', '.join(major_data['suitable_positions'])}\n"
                          f"æ ¸å¿ƒæŠ€èƒ½: {major_data['core_skills']}\n"
                          f"èŒä¸šè·¯å¾„: {major_data['career_paths']}")
    
    # Query by position (if not already found)
    if user_inputs['target_position'] and not user_inputs['target_industry']:
        position_data = knowledge_db.query('position', user_inputs['target_position'])
        if position_data:
            results.append(f"å²—ä½è¯¦æƒ… - {user_inputs['target_position']}:\n"
                          f"æ‰€éœ€æŠ€èƒ½: {position_data['skills']}\n"
                          f"å­¦å†è¦æ±‚: {position_data['education']}\n"
                          f"è–ªèµ„èŒƒå›´: {position_data['salary']}\n"
                          f"å‘å±•å‰æ™¯: {position_data['prospects']}")
    
    return "\n\n".join(results) if results else "çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯"

# Function to generate career planning draft with LangSmith tracking
def generate_career_planning_draft(user_inputs, agent_settings):
    try:
        # Initialize LangSmith if enabled
        langsmith_client = init_langsmith()
        
        # Query the knowledge database
        kb_data = query_knowledge_db(user_inputs)
        
        # Prepare the prompt for the career planning assistant
        role = agent_settings["role"]
        task = agent_settings["task"]
        output_format = agent_settings["output_format"]
        model = agent_settings["model"]
        
        user_info = f"""
        ç”¨æˆ·ä¿¡æ¯:
        - æœ¬ç§‘é™¢æ ¡: {user_inputs['university']}
        - æœ¬ç§‘ä¸“ä¸š: {user_inputs['major']}
        - æ„å‘è¡Œä¸š: {user_inputs['target_industry']}
        - æ„å‘å²—ä½: {user_inputs['target_position']}
        
        æˆç»©å•ä¿¡æ¯:
        {user_inputs['transcript_text']}
        
        çŸ¥è¯†åº“ä¿¡æ¯:
        {kb_data}
        """
        
        messages = [
            {"role": "system", "content": f"{role}\n\n{task}\n\nè¾“å‡ºæ ¼å¼è¦æ±‚:\n{output_format}"},
            {"role": "user", "content": user_info}
        ]
        
        # Track with LangSmith if available
        if langsmith_client:
            run_tree = RunTree(
                name="career_planning_draft",
                run_type="chain",
                inputs={"user_inputs": user_inputs, "agent_settings": agent_settings},
                client=langsmith_client
            )
            
            with run_tree:
                # Make API call through OpenRouter
                response = call_openrouter(
                    messages=messages, 
                    model=model, 
                    temperature=0.7
                )
                run_tree.end(outputs={"draft_report": response})
                return response
        else:
            # Make API call without tracking
            return call_openrouter(
                messages=messages, 
                model=model, 
                temperature=0.7
            )
    except Exception as e:
        return f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"

# Function to generate final career planning report with LangSmith tracking
def generate_final_report(draft_report, agent_settings):
    try:
        # Initialize LangSmith if enabled
        langsmith_client = init_langsmith()
        
        # Prepare the prompt for the submission agent
        role = agent_settings["role"]
        task = agent_settings["task"]
        output_format = agent_settings["output_format"]
        model = agent_settings["model"]
        
        messages = [
            {"role": "system", "content": f"{role}\n\n{task}\n\nè¾“å‡ºæ ¼å¼è¦æ±‚:\n{output_format}\n\nè¯·åœ¨é€‚å½“çš„åœ°æ–¹åŠ å…¥Mermaidå›¾è¡¨ï¼Œç”¨```mermaidå’Œ```åŒ…è£¹å›¾è¡¨ä»£ç ã€‚"},
            {"role": "user", "content": f"è¿™æ˜¯èŒä¸šè§„åˆ’æŠ¥å‘Šåˆç¨¿:\n\n{draft_report}\n\nè¯·åŸºäºæ­¤åˆç¨¿ï¼Œè¡¥å……ç›¸å…³ä¿¡æ¯ï¼Œå¹¶åˆ¶ä½œä¸€ä»½åŒ…å«æ–‡å­—å’Œå›¾è¡¨çš„å®Œæ•´æŠ¥å‘Šã€‚"}
        ]
        
        # Track with LangSmith if available
        if langsmith_client:
            run_tree = RunTree(
                name="final_report_generation",
                run_type="chain",
                inputs={"draft_report": draft_report, "agent_settings": agent_settings},
                client=langsmith_client
            )
            
            with run_tree:
                # Make API call through OpenRouter
                response = call_openrouter(
                    messages=messages, 
                    model=model, 
                    temperature=0.7
                )
                run_tree.end(outputs={"final_report": response})
                return response
        else:
            # Make API call without tracking
            return call_openrouter(
                messages=messages, 
                model=model, 
                temperature=0.7
            )
    except Exception as e:
        return f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"

# Main application interface
st.title("èŒä¸šè§„åˆ’åŠ©ç†")

# Create tabs
tab1, tab2, tab3 = st.tabs(["ä¿¡æ¯æ”¶é›†", "åŠ©ç†è®¾ç½®", "APIçŠ¶æ€"])

# Tab 1: Information Collection
with tab1:
    st.header("ç”¨æˆ·ä¿¡æ¯æ”¶é›†")
    
    col1, col2 = st.columns(2)
    
    with col1:
        university = st.text_input("æœ¬ç§‘é™¢æ ¡", value=st.session_state.user_inputs["university"])
        major = st.text_input("æœ¬ç§‘ä¸“ä¸š", value=st.session_state.user_inputs["major"])
    
    with col2:
        target_industry = st.text_input("æ„å‘è¡Œä¸š", value=st.session_state.user_inputs["target_industry"])
        target_position = st.text_input("æ„å‘å²—ä½", value=st.session_state.user_inputs["target_position"])
    
    # Transcript upload
    uploaded_file = st.file_uploader("ä¸Šä¼ æˆç»©å•ï¼ˆä»…æ”¯æŒå›¾ç‰‡æ ¼å¼ï¼‰", type=['png', 'jpg', 'jpeg'])
    
    transcript_text = ""
    if uploaded_file is not None:
        # Read the file
        image_bytes = uploaded_file.getvalue()
        
        # Call Qwen VL model to analyze the transcript
        with st.spinner("æ­£åœ¨åˆ†ææˆç»©å•..."):
            transcript_text = analyze_transcript_with_qwen(image_bytes)
        
        # Display the analysis result in an expandable section
        with st.expander("æˆç»©å•åˆ†æç»“æœ", expanded=True):
            st.write(transcript_text)
    
    # Store user inputs in session state
    if st.button("å¼€å§‹åˆ†æ"):
        # Validate inputs
        if not (major or target_industry or target_position):
            st.error("é”™è¯¯ï¼šæœ¬ç§‘ä¸“ä¸šã€æ„å‘è¡Œä¸šå’Œæ„å‘å²—ä½å¿…é¡»è‡³å°‘å¡«å†™ä¸€é¡¹")
        else:
            st.session_state.user_inputs = {
                "university": university,
                "major": major,
                "target_industry": target_industry,
                "target_position": target_position,
                "transcript_text": transcript_text
            }
            
            # Generate career planning draft
            with st.spinner("æ­£åœ¨ç”ŸæˆèŒä¸šè§„åˆ’æŠ¥å‘Šè‰ç¨¿..."):
                draft_report = generate_career_planning_draft(
                    st.session_state.user_inputs,
                    st.session_state.career_agent_settings
                )
                st.session_state.draft_report = draft_report
            
            # Display the draft report
            st.subheader("èŒä¸šè§„åˆ’æŠ¥å‘Šè‰ç¨¿")
            st.write(st.session_state.draft_report)
            
            # Generate final report
            with st.spinner("æ­£åœ¨ç”Ÿæˆæœ€ç»ˆèŒä¸šè§„åˆ’æŠ¥å‘Š..."):
                final_report = generate_final_report(
                    st.session_state.draft_report,
                    st.session_state.submission_agent_settings
                )
                st.session_state.final_report = final_report
            
            # Display the final report
            st.subheader("æœ€ç»ˆèŒä¸šè§„åˆ’æŠ¥å‘Š")
            
            # Process and display text and Mermaid diagrams separately
            report_parts = st.session_state.final_report.split("```mermaid")
            
            for i, part in enumerate(report_parts):
                if i == 0:
                    # First part is just text
                    st.write(part)
                else:
                    # Subsequent parts contain mermaid code followed by text
                    code_and_text = part.split("```", 1)
                    if len(code_and_text) == 2:
                        mermaid_code = code_and_text[0]
                        text = code_and_text[1]
                        
                        # Render the Mermaid diagram
                        render_mermaid(mermaid_code)
                        
                        # Display the text that follows
                        st.write(text)

# Tab 2: Agent Settings
with tab2:
    st.header("åŠ©ç†è®¾ç½®")
    
    st.subheader("èŒä¸šè§„åˆ’åŠ©ç†è®¾ç½®")
    career_role = st.text_area("äººç‰©è®¾å®š", value=st.session_state.career_agent_settings["role"], height=100)
    career_task = st.text_area("ä»»åŠ¡æè¿°", value=st.session_state.career_agent_settings["task"], height=100)
    career_output_format = st.text_area("è¾“å‡ºæ ¼å¼", value=st.session_state.career_agent_settings["output_format"], height=150)
    
    # Add model selection dropdown for career planning agent
    career_model = st.selectbox(
        "é€‰æ‹©èŒä¸šè§„åˆ’åŠ©ç†æ¨¡å‹", 
        options=list(AVAILABLE_MODELS.keys()),
        format_func=lambda x: AVAILABLE_MODELS[x],
        index=list(AVAILABLE_MODELS.keys()).index(st.session_state.career_agent_settings["model"])
    )
    
    st.subheader("äº¤ç¨¿åŠ©ç†è®¾ç½®")
    submission_role = st.text_area("äººç‰©è®¾å®š", value=st.session_state.submission_agent_settings["role"], height=100)
    submission_task = st.text_area("ä»»åŠ¡æè¿°", value=st.session_state.submission_agent_settings["task"], height=100)
    submission_output_format = st.text_area("è¾“å‡ºæ ¼å¼", value=st.session_state.submission_agent_settings["output_format"], height=150)
    
    # Add model selection dropdown for submission agent
    submission_model = st.selectbox(
        "é€‰æ‹©äº¤ç¨¿åŠ©ç†æ¨¡å‹", 
        options=list(AVAILABLE_MODELS.keys()),
        format_func=lambda x: AVAILABLE_MODELS[x],
        index=list(AVAILABLE_MODELS.keys()).index(st.session_state.submission_agent_settings["model"])
    )
    
    if st.button("ä¿å­˜è®¾ç½®"):
        st.session_state.career_agent_settings = {
            "role": career_role,
            "task": career_task,
            "output_format": career_output_format,
            "model": career_model
        }
        
        st.session_state.submission_agent_settings = {
            "role": submission_role,
            "task": submission_task,
            "output_format": submission_output_format,
            "model": submission_model
        }
        
        st.success("è®¾ç½®å·²ä¿å­˜")

# Tab 3: API Status
with tab3:
    st.header("APIçŠ¶æ€æ£€æµ‹")
    
    if st.button("æ£€æµ‹APIçŠ¶æ€"):
        with st.spinner("æ­£åœ¨æ£€æµ‹APIçŠ¶æ€..."):
            check_api_status()
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            status = "âœ… æ­£å¸¸" if st.session_state.api_status["openrouter"] else "âŒ å¼‚å¸¸"
            st.metric("OpenRouter API", status)
            
            if not st.session_state.api_status["openrouter"]:
                st.warning("è¯·æ£€æŸ¥Streamlit Secretsä¸­çš„OPENROUTER_API_KEYæ˜¯å¦æ­£ç¡®è®¾ç½®")
        
        with col2:
            status = "âœ… æ­£å¸¸" if st.session_state.api_status["qwen"] else "âŒ å¼‚å¸¸"
            st.metric("Qwen API", status)
            
            if not st.session_state.api_status["qwen"]:
                st.warning("è¯·æ£€æŸ¥Streamlit Secretsä¸­çš„QWEN_API_KEYæ˜¯å¦æ­£ç¡®è®¾ç½®")
        
        with col3:
            status = "âœ… æ­£å¸¸" if st.session_state.api_status["langsmith"] else "âŒ å¼‚å¸¸"
            st.metric("LangSmith", status)
            
            if not st.session_state.api_status["langsmith"]:
                st.warning("è¯·æ£€æŸ¥Streamlit Secretsä¸­çš„LANGSMITH_API_KEYæ˜¯å¦æ­£ç¡®è®¾ç½®") 