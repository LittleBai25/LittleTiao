import streamlit as st
import os
from PIL import Image
import io
import pandas as pd
import base64
from dotenv import load_dotenv
import requests
import json
from langchain.agents import AgentExecutor, create_react_agent
from langchain_core.tools import Tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langsmith import Client
from langsmith.run_trees import RunTree
import tempfile
import streamlit.components.v1 as components
import datetime

# Load environment variables
load_dotenv()

# Page configuration
st.set_page_config(
    page_title="Career Planning Assistant",
    page_icon="ğŸš€",
    layout="wide"
)

# Available models with full names
AVAILABLE_MODELS = {
    "qwen/qwen-max": "Qwen Max",
    "qwen/qwen3-32b:free": "Qwen 3 32B",
    "deepseek/deepseek-chat-v3-0324:free": "DeepSeek Chat v3"
}

# Session state initialization
if 'user_inputs' not in st.session_state:
    st.session_state.user_inputs = {
        "university": "",
        "major": "",
        "target_industry": "",
        "target_position": "",
        "transcript_text": ""
    }

if 'career_agent_settings' not in st.session_state:
    st.session_state.career_agent_settings = {
        "role": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„èŒä¸šè§„åˆ’é¡¾é—®ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„è¡Œä¸šçŸ¥è¯†å’Œè§è§£ã€‚",
        "task": "åŸºäºç”¨æˆ·çš„å­¦æœ¯èƒŒæ™¯ã€ä¸“ä¸šã€æœŸæœ›è¿›å…¥çš„è¡Œä¸šå’ŒèŒä½ï¼Œåˆ†æä»–ä»¬çš„èŒä¸šå‘å±•è·¯å¾„ï¼Œå¹¶æä¾›å…·ä½“ã€å¯è¡Œçš„å»ºè®®ã€‚",
        "output_format": "è¯·æä¾›ç»“æ„åŒ–çš„èŒä¸šè§„åˆ’åˆ†æï¼ŒåŒ…æ‹¬ï¼š\n1. èƒŒæ™¯åˆ†æ\n2. èŒä¸šè·¯å¾„å»ºè®®\n3. æŠ€èƒ½å‘å±•æ–¹å‘\n4. è¡Œä¸šå‰æ™¯\n5. çŸ­æœŸå’Œé•¿æœŸç›®æ ‡",
        "model": "qwen/qwen-max"
    }

if 'submission_agent_settings' not in st.session_state:
    st.session_state.submission_agent_settings = {
        "role": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„èŒä¸šè§„åˆ’æŠ¥å‘Šç¼–è¾‘ï¼Œæ“…é•¿æ•´åˆä¿¡æ¯å¹¶åˆ›å»ºè§†è§‰å¸å¼•åŠ›å¼ºçš„æŠ¥å‘Šã€‚",
        "task": "åŸºäºèŒä¸šè§„åˆ’è‰ç¨¿ï¼Œè¡¥å……ç›¸å…³è¡Œä¸šæ•°æ®å’Œä¿¡æ¯ï¼Œåˆ›å»ºä¸€ä»½åŒ…å«æ–‡å­—æè¿°å’Œå¯è§†åŒ–å†…å®¹çš„å®Œæ•´æŠ¥å‘Šã€‚",
        "output_format": "è¯·æä¾›ä¸“ä¸šçš„èŒä¸šè§„åˆ’æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š\n1. æ‰§è¡Œæ‘˜è¦\n2. è¯¦ç»†åˆ†æ\n3. æ•°æ®æ”¯æŒå›¾è¡¨\n4. è¡ŒåŠ¨è®¡åˆ’\n5. èµ„æºå»ºè®®",
        "model": "qwen/qwen-max"
    }

if 'draft_report' not in st.session_state:
    st.session_state.draft_report = ""

if 'final_report' not in st.session_state:
    st.session_state.final_report = ""

if 'api_status' not in st.session_state:
    st.session_state.api_status = {
        "openrouter": False,
        "langsmith": False
    }

# Simulated knowledge database
class KnowledgeDatabase:
    def __init__(self):
        # This would be replaced with an actual database connection in production
        self.data = {
            "industries": {
                "IT/Internet": {
                    "positions": [
                        {
                            "name": "Software Engineer",
                            "skills": "Python, Java, JavaScript, Data Structures, Algorithms",
                            "education": "Bachelor's degree or above in Computer Science/Software Engineering",
                            "salary": "$80K-$150K",
                            "prospects": "Continuous industry demand, broad development space"
                        },
                        {
                            "name": "Frontend Developer",
                            "skills": "HTML, CSS, JavaScript, React/Vue/Angular, TypeScript",
                            "education": "Bachelor's degree or above in Computer Science related majors",
                            "salary": "$70K-$130K",
                            "prospects": "High demand with continuous internet product development"
                        },
                        {
                            "name": "Data Analyst",
                            "skills": "SQL, Python, R, Excel, Data Visualization, Statistics",
                            "education": "Bachelor's degree or above in Statistics/Mathematics/Computer Science",
                            "salary": "$75K-$140K",
                            "prospects": "Scarce talent in the big data era, good development prospects"
                        }
                    ],
                    "overview": "The IT/Internet industry has fast technology updates and fierce competition, but offers high salary levels and development space"
                },
                "Finance": {
                    "positions": [
                        {
                            "name": "Investment Analyst",
                            "skills": "Financial Analysis, Valuation Models, Excel, Financial Market Knowledge",
                            "education": "Bachelor's degree or above in Finance/Economics/Accounting",
                            "salary": "$85K-$150K",
                            "prospects": "Stable financial industry with clear promotion paths"
                        },
                        {
                            "name": "Risk Control",
                            "skills": "Risk Assessment, Data Analysis, Regulatory Knowledge, Financial Instruments",
                            "education": "Bachelor's degree or above in Finance/Mathematics/Statistics",
                            "salary": "$90K-$160K",
                            "prospects": "Stable demand for risk control talent, good career development prospects"
                        }
                    ],
                    "overview": "The financial industry is relatively stable, emphasizing professionalism and compliance, with a mature career development system"
                }
            },
            "majors": {
                "Computer Science": {
                    "suitable_industries": ["IT/Internet", "Finance", "Education"],
                    "suitable_positions": ["Software Engineer", "Data Analyst", "IT Consultant"],
                    "core_skills": "Programming Languages, Data Structures, Algorithms, Databases, Network Fundamentals",
                    "career_paths": "Can develop from Developer to Architect, Technical Manager, or Product Manager"
                },
                "Finance": {
                    "suitable_industries": ["Finance", "Consulting", "Corporate Finance"],
                    "suitable_positions": ["Investment Analyst", "Risk Control", "Financial Advisor"],
                    "core_skills": "Financial Analysis, Financial Markets, Risk Management, Investment Theory",
                    "career_paths": "Can develop from Analyst to Investment Manager, Risk Manager, or CFO"
                }
            }
        }
    
    def query(self, query_type, query_value):
        """
        Query the database with different query types
        query_type can be: 'industry', 'position', 'major'
        """
        if query_type == 'industry' and query_value in self.data['industries']:
            return self.data['industries'][query_value]
        elif query_type == 'major' and query_value in self.data['majors']:
            return self.data['majors'][query_value]
        elif query_type == 'position':
            # Search for position across all industries
            for industry, industry_data in self.data['industries'].items():
                for position in industry_data['positions']:
                    if position['name'] == query_value:
                        return position
            return None
        else:
            return None

# Initialize knowledge database
knowledge_db = KnowledgeDatabase()

# Function to check API status
def check_api_status():
    # Check OpenRouter API
    try:
        openrouter_key = st.secrets.get("OPENROUTER_API_KEY")
        if openrouter_key:
            headers = {
                "Authorization": f"Bearer {openrouter_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://career-planner.streamlit.app"
            }
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json={
                    "model": "qwen/qwen-max",  # Use a default model
                    "messages": [{"role": "user", "content": "Hello"}],
                    "max_tokens": 5
                }
            )
            st.session_state.api_status["openrouter"] = response.status_code == 200
        else:
            st.session_state.api_status["openrouter"] = False
    except Exception as e:
        st.error(f"OpenRouter API error: {str(e)}")
        st.session_state.api_status["openrouter"] = False
    
    # Check LangSmith status
    try:
        langsmith_key = st.secrets.get("LANGSMITH_API_KEY")
        if langsmith_key:
            # ç¡®ä¿ç¯å¢ƒå˜é‡è®¾ç½®æ­£ç¡®
            os.environ["LANGSMITH_API_KEY"] = langsmith_key
            os.environ["LANGCHAIN_PROJECT"] = st.secrets.get("LANGSMITH_PROJECT", "career-planner")
            os.environ["LANGCHAIN_TRACING_V2"] = "true"
            os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"  # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ç«¯ç‚¹
            
            # åˆ›å»ºå®¢æˆ·ç«¯å¹¶æµ‹è¯•è¿æ¥ (ä»…åœ¨APIçŠ¶æ€é¡µé¢æ˜¾ç¤ºæ¶ˆæ¯)
            client = Client(api_key=langsmith_key)
            
            # ç®€å•åœ°ä½¿ç”¨APIè°ƒç”¨æ¥éªŒè¯è¿æ¥ï¼Œä¸ä½¿ç”¨get_projectæ–¹æ³•
            try:
                # å°è¯•åˆ›å»ºä¸€ä¸ªç®€å•çš„è¿è¡Œæ¥æµ‹è¯•APIè¿æ¥
                run_tree = RunTree(
                    name="test_connection",
                    run_type="chain",
                    inputs={"test": "connection"},
                    client=client
                )
                run_tree.post()
                run_tree.end(outputs={"result": "success"})
                st.session_state.api_status["langsmith"] = True
                # ä¸æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯ï¼Œåªåœ¨APIçŠ¶æ€é¡µé¢æ˜¾ç¤º
            except Exception as inner_e:
                st.error(f"LangSmith APIè¿æ¥æµ‹è¯•å¤±è´¥: {str(inner_e)}")
                st.session_state.api_status["langsmith"] = False
        else:
            st.session_state.api_status["langsmith"] = False
            st.warning("LangSmith APIå¯†é’¥æœªè®¾ç½®")
    except Exception as e:
        st.error(f"LangSmith API error: {str(e)}")
        st.session_state.api_status["langsmith"] = False

# Initialize LangSmith client if enabled
def init_langsmith():
    try:
        langsmith_api_key = st.secrets.get("LANGSMITH_API_KEY")
        if not langsmith_api_key:
            # ä¸åœ¨UIä¸­æ˜¾ç¤ºè­¦å‘Šï¼Œåªè¿”å›None
            return None
            
        langsmith_project = st.secrets.get("LANGSMITH_PROJECT", "career-planner") 
        # è®¾ç½®æ‰€æœ‰å¿…è¦çš„ç¯å¢ƒå˜é‡
        os.environ["LANGSMITH_API_KEY"] = langsmith_api_key
        os.environ["LANGCHAIN_PROJECT"] = langsmith_project or "default"
        os.environ["LANGCHAIN_TRACING_V2"] = "true"
        os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
        # æ·»åŠ é¢å¤–çš„å¿…è¦ç¯å¢ƒå˜é‡
        os.environ["LANGCHAIN_API_KEY"] = langsmith_api_key  # å…¼å®¹æ€§
        
        # åˆ›å»ºå¹¶è¿”å›å®¢æˆ·ç«¯ - ä¸æ˜¾ç¤ºä»»ä½•UIæ¶ˆæ¯
        return Client(api_key=langsmith_api_key) 
    except Exception as e:
        # åªåœ¨Debugæ¨¡å¼ä¸‹è®°å½•é”™è¯¯ï¼Œä¸æ˜¾ç¤ºUIæ¶ˆæ¯
        print(f"LangSmithåˆå§‹åŒ–é”™è¯¯: {str(e)}")
        return None

# æ·»åŠ æ–°çš„LangSmithè¿½è¸ªå·¥å…·å‡½æ•°
def log_to_langsmith(name, inputs, outputs=None, error=None, parent_run_id=None):
    """ä½¿ç”¨ç›´æ¥APIè°ƒç”¨è®°å½•åˆ°LangSmith"""
    try:
        api_key = os.environ.get("LANGSMITH_API_KEY")
        if not api_key:
            print("æ²¡æœ‰æ‰¾åˆ°LangSmith APIå¯†é’¥")
            return None
            
        project_name = os.environ.get("LANGCHAIN_PROJECT", "career-planner")
        
        # å‡†å¤‡åŸºæœ¬çš„è¿è¡Œæ•°æ®
        run_data = {
            "name": name,
            "run_type": "chain",
            "inputs": inputs,
            "project_name": project_name,
            "start_time": datetime.datetime.utcnow().isoformat() + "Z"
        }
        
        # å¦‚æœæœ‰çˆ¶è¿è¡ŒIDï¼Œæ·»åŠ åˆ°æ•°æ®ä¸­
        if parent_run_id:
            run_data["parent_run_id"] = parent_run_id
            
        # å‘é€åˆ›å»ºè¿è¡Œçš„è¯·æ±‚
        response = requests.post(
            "https://api.smith.langchain.com/runs",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            },
            json=run_data
        )
        
        if response.status_code != 200:
            print(f"åˆ›å»ºLangSmithè¿è¡Œå¤±è´¥: {response.status_code} - {response.text}")
            return None
            
        # è·å–è¿è¡ŒID
        run_id = response.json().get("id")
        print(f"æˆåŠŸåˆ›å»ºLangSmithè¿è¡Œ: {run_id}, åç§°: {name}")
        
        # å¦‚æœæä¾›äº†è¾“å‡ºæˆ–é”™è¯¯ï¼Œç«‹å³ç»“æŸè¿è¡Œ
        if outputs is not None or error is not None:
            end_data = {
                "end_time": datetime.datetime.utcnow().isoformat() + "Z"
            }
            
            if outputs is not None:
                end_data["outputs"] = outputs
                end_data["status"] = "success"
            elif error is not None:
                end_data["error"] = str(error)
                end_data["status"] = "error"
                
            # å‘é€ç»“æŸè¿è¡Œçš„è¯·æ±‚
            end_response = requests.patch(
                f"https://api.smith.langchain.com/runs/{run_id}",
                headers={
                    "Authorization": f"Bearer {api_key}",
                    "Content-Type": "application/json"
                },
                json=end_data
            )
            
            if end_response.status_code != 200:
                print(f"ç»“æŸLangSmithè¿è¡Œå¤±è´¥: {end_response.status_code} - {end_response.text}")
        
        return run_id
    except Exception as e:
        print(f"LangSmith APIè°ƒç”¨é”™è¯¯: {str(e)}")
        return None

# ä¿®æ”¹è°ƒç”¨OpenRouterçš„å‡½æ•°ï¼Œé›†æˆLangSmithæ—¥å¿—
def call_openrouter(messages, model, temperature=0.7, is_vision=False, run_name="openrouter_call", parent_run_id=None):
    run_id = None
    start_time = datetime.datetime.utcnow()
    
    try:
        api_key = st.secrets.get("OPENROUTER_API_KEY")
        if not api_key:
            return "Error: OpenRouter API key not set"
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://career-planner.streamlit.app"  # Replace with your actual domain
        }
        
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature
        }
        
        # è®°å½•LLMè°ƒç”¨å¼€å§‹
        run_id = log_to_langsmith(
            name=run_name,
            inputs={
                "messages": messages, 
                "model": model,
                "temperature": temperature
            },
            parent_run_id=parent_run_id
        )
        
        # å‘é€APIè¯·æ±‚
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=payload
        )
        
        result = response.json()
        
        # æå–å“åº”å†…å®¹
        if "choices" in result and len(result["choices"]) > 0:
            content = result["choices"][0]["message"]["content"]
            
            # è®°å½•æˆåŠŸçš„ç»“æœ
            if run_id:
                log_to_langsmith(
                    name=f"{run_name}_end",
                    inputs={},
                    outputs={"content": content},
                    parent_run_id=run_id
                )
                
                # æ›´æ–°çˆ¶è¿è¡Œ
                end_time = datetime.datetime.utcnow()
                duration_ms = int((end_time - start_time).total_seconds() * 1000)
                
                requests.patch(
                    f"https://api.smith.langchain.com/runs/{run_id}",
                    headers={
                        "Authorization": f"Bearer {os.environ.get('LANGSMITH_API_KEY')}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "end_time": end_time.isoformat() + "Z",
                        "status": "success",
                        "outputs": {"content": content[:1000] + ("..." if len(content) > 1000 else "")},
                        "metrics": {
                            "tokens": len(content.split()) * 1.3,  # ä¼°ç®—
                            "duration_ms": duration_ms
                        }
                    }
                )
            
            return content
        else:
            error_msg = f"Request failed: {str(result)}"
            
            # è®°å½•é”™è¯¯
            if run_id:
                requests.patch(
                    f"https://api.smith.langchain.com/runs/{run_id}",
                    headers={
                        "Authorization": f"Bearer {os.environ.get('LANGSMITH_API_KEY')}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "end_time": datetime.datetime.utcnow().isoformat() + "Z",
                        "status": "error",
                        "error": error_msg
                    }
                )
            
            return error_msg
    except Exception as e:
        error_msg = f"Error during request: {str(e)}"
        
        # è®°å½•å¼‚å¸¸
        if run_id:
            requests.patch(
                f"https://api.smith.langchain.com/runs/{run_id}",
                headers={
                    "Authorization": f"Bearer {os.environ.get('LANGSMITH_API_KEY')}",
                    "Content-Type": "application/json"
                },
                json={
                    "end_time": datetime.datetime.utcnow().isoformat() + "Z",
                    "status": "error",
                    "error": error_msg
                }
            )
        
        return error_msg

# Function to analyze transcript with vision model through OpenRouter
def analyze_transcript_with_vision_model(image_bytes):
    try:
        api_key = st.secrets.get("OPENROUTER_API_KEY")
        if not api_key:
            return "Error: OpenRouter API key not set"
        
        # Convert image to base64
        base64_image = base64.b64encode(image_bytes).decode('utf-8')
        
        # Create message with image
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "This is a transcript. Please identify and extract all course names, credits, and grade information, and organize them into a table format."},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                ]
            }
        ]
        
        # Use Qwen's vision model through OpenRouter
        return call_openrouter(messages, "qwen/qwen2.5-vl-72b-instruct", temperature=0.3, is_vision=True)
    except Exception as e:
        return f"Error during analysis: {str(e)}"

# Function to render Mermaid diagrams
def render_mermaid(mermaid_code):
    # æ¸…ç†å¯èƒ½åŒ…å«çš„ç©ºæ ¼æˆ–ç‰¹æ®Šå­—ç¬¦
    mermaid_code = mermaid_code.strip()
    
    html = f"""
    <div class="mermaid">
    {mermaid_code}
    </div>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({{ 
            startOnLoad: true,
            theme: 'default',
            securityLevel: 'loose',
            logLevel: 'error'
        }});
    </script>
    """
    components.html(html, height=500)

# Function to query knowledge database
def query_knowledge_db(user_inputs):
    results = []
    
    # Query by industry
    if user_inputs['target_industry']:
        industry_data = knowledge_db.query('industry', user_inputs['target_industry'])
        if industry_data:
            results.append(f"Industry Overview - {user_inputs['target_industry']}:\n{industry_data['overview']}")
            
            # If position is specified, find specific position data
            if user_inputs['target_position']:
                for position in industry_data['positions']:
                    if position['name'] == user_inputs['target_position']:
                        results.append(f"Position Details - {position['name']}:\n"
                                      f"Required Skills: {position['skills']}\n"
                                      f"Education Requirements: {position['education']}\n"
                                      f"Salary Range: {position['salary']}\n"
                                      f"Career Prospects: {position['prospects']}")
                        break
            else:
                # List all positions in this industry
                results.append(f"Popular Positions in {user_inputs['target_industry']}:")
                for position in industry_data['positions']:
                    results.append(f"- {position['name']}: {position['prospects']}")
    
    # Query by major
    if user_inputs['major']:
        major_data = knowledge_db.query('major', user_inputs['major'])
        if major_data:
            results.append(f"Career Directions for {user_inputs['major']} Major:\n"
                          f"Suitable Industries: {', '.join(major_data['suitable_industries'])}\n"
                          f"Suitable Positions: {', '.join(major_data['suitable_positions'])}\n"
                          f"Core Skills: {major_data['core_skills']}\n"
                          f"Career Paths: {major_data['career_paths']}")
    
    # Query by position (if not already found)
    if user_inputs['target_position'] and not user_inputs['target_industry']:
        position_data = knowledge_db.query('position', user_inputs['target_position'])
        if position_data:
            results.append(f"Position Details - {user_inputs['target_position']}:\n"
                          f"Required Skills: {position_data['skills']}\n"
                          f"Education Requirements: {position_data['education']}\n"
                          f"Salary Range: {position_data['salary']}\n"
                          f"Career Prospects: {position_data['prospects']}")
    
    return "\n\n".join(results) if results else "No relevant information found in the knowledge base"

# Function to generate career planning draft with LangSmith tracking
def generate_career_planning_draft(user_inputs, agent_settings):
    try:
        # ç¡®ä¿ç¯å¢ƒå˜é‡è®¾ç½®æ­£ç¡®
        langsmith_api_key = st.secrets.get("LANGSMITH_API_KEY")
        if langsmith_api_key:
            os.environ["LANGSMITH_API_KEY"] = langsmith_api_key
            os.environ["LANGCHAIN_PROJECT"] = st.secrets.get("LANGSMITH_PROJECT", "career-planner")
            os.environ["LANGCHAIN_TRACING_V2"] = "true"
            
        # å¼€å§‹è®°å½•æ•´ä¸ªèŒä¸šè§„åˆ’è¿‡ç¨‹
        parent_run_id = log_to_langsmith(
            name="èŒä¸šè§„åˆ’åˆ†ææµç¨‹",
            inputs={
                "university": user_inputs["university"],
                "major": user_inputs["major"],
                "target_industry": user_inputs["target_industry"],
                "target_position": user_inputs["target_position"]
            }
        )
        
        # Query the knowledge database
        kb_data = query_knowledge_db(user_inputs)
        
        # è®°å½•çŸ¥è¯†åº“æŸ¥è¯¢
        kb_run_id = log_to_langsmith(
            name="çŸ¥è¯†åº“æŸ¥è¯¢",
            inputs=user_inputs,
            outputs={"knowledge_data": kb_data},
            parent_run_id=parent_run_id
        )
        
        # Prepare the prompt for the career planning assistant
        role = agent_settings["role"]
        task = agent_settings["task"]
        output_format = agent_settings["output_format"]
        model = agent_settings["model"]
        
        user_info = f"""
        ç”¨æˆ·ä¿¡æ¯:
        - å¤§å­¦: {user_inputs['university']}
        - ä¸“ä¸š: {user_inputs['major']}
        - ç›®æ ‡è¡Œä¸š: {user_inputs['target_industry']}
        - ç›®æ ‡èŒä½: {user_inputs['target_position']}
        
        æˆç»©å•ä¿¡æ¯:
        {user_inputs['transcript_text']}
        
        çŸ¥è¯†åº“ä¿¡æ¯:
        {kb_data}
        """
        
        messages = [
            {"role": "system", "content": f"{role}\n\n{task}\n\nè¾“å‡ºæ ¼å¼è¦æ±‚:\n{output_format}"},
            {"role": "user", "content": user_info}
        ]
        
        # åˆ›å»ºèŒä¸šè§„åˆ’è‰ç¨¿
        draft_run_id = log_to_langsmith(
            name="ç”ŸæˆèŒä¸šè§„åˆ’è‰ç¨¿",
            inputs={"messages": messages},
            parent_run_id=parent_run_id
        )
        
        # Make API call through OpenRouter
        response = call_openrouter(
            messages=messages, 
            model=model, 
            temperature=0.7,
            run_name="èŒä¸šè§„åˆ’AIè°ƒç”¨",
            parent_run_id=draft_run_id
        )
        
        # æ›´æ–°è‰ç¨¿è¿è¡Œçš„ç»“æœ
        log_to_langsmith(
            name="èŒä¸šè§„åˆ’è‰ç¨¿ç»“æœ",
            inputs={},
            outputs={"draft": response[:1000] + ("..." if len(response) > 1000 else "")},
            parent_run_id=draft_run_id
        )
        
        return response
    except Exception as e:
        error_msg = f"æŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        print(error_msg)
        return error_msg

# Function to generate final career planning report with LangSmith tracking
def generate_final_report(draft_report, agent_settings):
    try:
        # ç¡®ä¿ç¯å¢ƒå˜é‡è®¾ç½®æ­£ç¡®
        langsmith_api_key = st.secrets.get("LANGSMITH_API_KEY")
        if langsmith_api_key:
            os.environ["LANGSMITH_API_KEY"] = langsmith_api_key
            os.environ["LANGCHAIN_PROJECT"] = st.secrets.get("LANGSMITH_PROJECT", "career-planner")
            os.environ["LANGCHAIN_TRACING_V2"] = "true"
            
        # å¼€å§‹è®°å½•æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹
        parent_run_id = log_to_langsmith(
            name="æœ€ç»ˆèŒä¸šè§„åˆ’æŠ¥å‘Šç”Ÿæˆ",
            inputs={"draft_length": len(draft_report)}
        )
        
        # Prepare the prompt for the submission agent
        role = agent_settings["role"]
        task = agent_settings["task"]
        output_format = agent_settings["output_format"]
        model = agent_settings["model"]
        
        # æ›´æ–°ç³»ç»Ÿæç¤ºï¼Œæä¾›æ›´ç®€å•çš„Mermaidå›¾è¡¨ç¤ºä¾‹å’Œæ›´ä¸¥æ ¼çš„è¯­æ³•è¦æ±‚
        system_prompt = f"""{role}

{task}

è¾“å‡ºæ ¼å¼è¦æ±‚:
{output_format}

è¯·åœ¨é€‚å½“çš„ä½ç½®åŒ…å«Mermaidå›¾è¡¨ã€‚åˆ›å»ºMermaidå›¾è¡¨æ—¶ï¼Œè¯·æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š
1. å°†å›¾è¡¨ä»£ç åŒ…è£¹åœ¨```mermaidå’Œ```æ ‡ç­¾ä¸­
2. ä½¿ç”¨éå¸¸ç®€å•çš„Mermaidè¯­æ³•ï¼Œé¿å…å¤æ‚çš„åŠŸèƒ½
3. åˆ›å»ºä¸€ä¸ªç®€å•çš„èŒä¸šè·¯å¾„æµç¨‹å›¾
4. å›¾è¡¨ä¸­åªä½¿ç”¨åŸºæœ¬èŠ‚ç‚¹å’Œè¿æ¥ï¼Œä¸è¦ä½¿ç”¨å¤æ‚æ ·å¼
5. é¿å…åœ¨èŠ‚ç‚¹æ–‡å­—ä¸­ä½¿ç”¨ç‰¹æ®Šå­—ç¬¦å’Œæ ‡ç‚¹ç¬¦å·
6. æ‰€æœ‰èŠ‚ç‚¹å¿…é¡»æœ‰è¿æ¥ï¼Œä¸èƒ½æœ‰å­¤ç«‹èŠ‚ç‚¹

éå¸¸ç®€å•çš„æœ‰æ•ˆMermaidä»£ç ç¤ºä¾‹ï¼š
```mermaid
flowchart TD
    A[å¼€å§‹] --> B[å­¦ä¹ ]
    B --> C[å·¥ä½œ]
```

æ³¨æ„ï¼šè¯·ç¡®ä¿ä½¿ç”¨æœ€ç®€å•çš„è¯­æ³•åˆ›å»ºå›¾è¡¨ï¼Œé¿å…ä»»ä½•å¯èƒ½å¯¼è‡´è¯­æ³•é”™è¯¯çš„å¤æ‚åŠŸèƒ½ã€‚
æ‰€æœ‰å†…å®¹è¯·ä½¿ç”¨ä¸­æ–‡è¾“å‡ºã€‚
"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"è¿™æ˜¯èŒä¸šè§„åˆ’æŠ¥å‘Šè‰ç¨¿ï¼š\n\n{draft_report}\n\nåŸºäºè¿™ä»½è‰ç¨¿ï¼Œè¯·è¡¥å……ç›¸å…³ä¿¡æ¯ï¼Œåˆ›å»ºä¸€ä»½åŒ…å«æ–‡å­—å’Œä¸€ä¸ªç®€å•æµç¨‹å›¾çš„å®Œæ•´æŠ¥å‘Šã€‚å›¾è¡¨å¿…é¡»éå¸¸ç®€å•ï¼Œä»…ä½¿ç”¨åŸºæœ¬èŠ‚ç‚¹å’Œè¿æ¥ã€‚è¯·ç”¨ä¸­æ–‡è¾“å‡ºæ‰€æœ‰å†…å®¹ã€‚"}
        ]
        
        # è®°å½•æŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹
        report_gen_run_id = log_to_langsmith(
            name="æ ¼å¼åŒ–æœ€ç»ˆæŠ¥å‘Š",
            inputs={"system_prompt_length": len(system_prompt)},
            parent_run_id=parent_run_id
        )
        
        # Make API call through OpenRouter
        response = call_openrouter(
            messages=messages, 
            model=model, 
            temperature=0.7,
            run_name="æŠ¥å‘Šç”ŸæˆAIè°ƒç”¨",
            parent_run_id=report_gen_run_id
        )
        
        # æ›´æ–°æŠ¥å‘Šç”Ÿæˆç»“æœ
        log_to_langsmith(
            name="æœ€ç»ˆæŠ¥å‘Šç»“æœ",
            inputs={},
            outputs={"final_report_sample": response[:1000] + ("..." if len(response) > 1000 else "")},
            parent_run_id=report_gen_run_id
        )
        
        # ç»“æŸæœ€ç»ˆæŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹
        requests.patch(
            f"https://api.smith.langchain.com/runs/{parent_run_id}",
            headers={
                "Authorization": f"Bearer {os.environ.get('LANGSMITH_API_KEY')}",
                "Content-Type": "application/json"
            },
            json={
                "end_time": datetime.datetime.utcnow().isoformat() + "Z",
                "status": "success"
            }
        )
        
        return response
    except Exception as e:
        error_msg = f"æŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        print(error_msg)
        return error_msg

# Check API status on startup
check_api_status()

# Main application interface
st.title("Career Planning Assistant")

# Create tabs
tab1, tab2, tab3 = st.tabs(["Information Collection", "Agent Settings", "API Status"])

# Tab 1: Information Collection
with tab1:
    st.header("User Information Collection")
    
    col1, col2 = st.columns(2)
    
    with col1:
        university = st.text_input("University", value=st.session_state.user_inputs["university"])
        major = st.text_input("Major", value=st.session_state.user_inputs["major"])
    
    with col2:
        target_industry = st.text_input("Target Industry", value=st.session_state.user_inputs["target_industry"])
        target_position = st.text_input("Target Position", value=st.session_state.user_inputs["target_position"])
    
    # Transcript upload
    uploaded_file = st.file_uploader("Upload Transcript (Image formats only)", type=['png', 'jpg', 'jpeg'])
    
    transcript_text = ""
    if uploaded_file is not None:
        # Read the file
        image_bytes = uploaded_file.getvalue()
        
        # Call vision model to analyze the transcript
        with st.spinner("Analyzing transcript..."):
            transcript_text = analyze_transcript_with_vision_model(image_bytes)
        
        # Display the analysis result in an expandable section
        with st.expander("Transcript Analysis Result", expanded=True):
            st.write(transcript_text)
    
    # Store user inputs in session state
    if st.button("Start Analysis"):
        # Validate inputs
        if not (major or target_industry or target_position):
            st.error("Error: At least one of Major, Target Industry, or Target Position must be filled")
        else:
            st.session_state.user_inputs = {
                "university": university,
                "major": major,
                "target_industry": target_industry,
                "target_position": target_position,
                "transcript_text": transcript_text
            }
            
            # Generate career planning draft
            with st.spinner("Generating career planning report draft..."):
                draft_report = generate_career_planning_draft(
                    st.session_state.user_inputs,
                    st.session_state.career_agent_settings
                )
                st.session_state.draft_report = draft_report
            
            # Display the draft report
            st.subheader("Career Planning Report Draft")
            st.write(st.session_state.draft_report)
            
            # Generate final report
            with st.spinner("Generating final career planning report..."):
                final_report = generate_final_report(
                    st.session_state.draft_report,
                    st.session_state.submission_agent_settings
                )
                st.session_state.final_report = final_report
            
            # Display the final report
            st.subheader("Final Career Planning Report")
            
            # æ›´æ–°å¤„ç†å›¾è¡¨çš„æ–¹å¼ï¼Œæ·»åŠ æ›´å¤šå¥å£®æ€§
            try:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«Mermaidå›¾è¡¨
                if "```mermaid" in st.session_state.final_report:
                    # Process and display text and Mermaid diagrams separately
                    report_parts = st.session_state.final_report.split("```mermaid")
                    
                    # Display the first text part
                    if report_parts and len(report_parts) > 0:
                        st.write(report_parts[0])
                    
                    # Process each mermaid diagram and following text
                    for i in range(1, len(report_parts)):
                        part = report_parts[i]
                        # Split by the closing code block marker
                        if "```" in part:
                            mermaid_code, remaining_text = part.split("```", 1)
                            # Clean mermaid code and render
                            mermaid_code = mermaid_code.strip()
                            
                            # ä¸ºè°ƒè¯•æ·»åŠ ä¸€ä¸ªé€‰é¡¹æ¥æ˜¾ç¤ºåŸå§‹mermaidä»£ç 
                            with st.expander("æŸ¥çœ‹å›¾è¡¨ä»£ç "):
                                st.code(mermaid_code, language="mermaid")
                            
                            # å°è¯•ä¿®å¤å¸¸è§çš„è¯­æ³•é”™è¯¯
                            if "graph" in mermaid_code and "flowchart" not in mermaid_code:
                                # æ—§ç‰ˆè¯­æ³•ï¼Œè½¬æ¢ä¸ºæ–°ç‰ˆ
                                mermaid_code = mermaid_code.replace("graph", "flowchart")
                            
                            try:
                                # Render diagram with error handling
                                render_mermaid(mermaid_code)
                            except Exception as e:
                                st.error(f"å›¾è¡¨æ¸²æŸ“å¤±è´¥: {str(e)}")
                                st.code(mermaid_code, language="mermaid")
                                
                                # å°è¯•æ¸²æŸ“ä¸€ä¸ªå¤‡ç”¨çš„ç®€å•å›¾è¡¨
                                st.warning("å°è¯•æ¸²æŸ“å¤‡ç”¨å›¾è¡¨...")
                                try:
                                    fallback_code = """
flowchart TD
    A[å­¦ä¹ ] --> B[å®è·µ]
    B --> C[å°±ä¸š]
                                    """
                                    render_mermaid(fallback_code)
                                except:
                                    st.error("å¤‡ç”¨å›¾è¡¨ä¹Ÿæ¸²æŸ“å¤±è´¥")
                            
                            # Display the text that follows
                            st.write(remaining_text)
                        else:
                            # No closing marker found, just display as text
                            st.write(part)
                else:
                    # å¦‚æœæ²¡æœ‰å›¾è¡¨æ ‡è®°ï¼Œç›´æ¥æ˜¾ç¤ºæŠ¥å‘Š
                    st.write(st.session_state.final_report)
            except Exception as e:
                # å¦‚æœè§£æå¤±è´¥ï¼Œç›´æ¥æ˜¾ç¤ºå®Œæ•´æŠ¥å‘Š
                st.error(f"å¤„ç†å›¾è¡¨æ—¶å‡ºé”™: {str(e)}")
                st.write(st.session_state.final_report)

# Tab 2: Agent Settings
with tab2:
    st.header("Agent Settings")
    
    st.subheader("Career Planning Assistant Settings")
    career_role = st.text_area("Character Setting", value=st.session_state.career_agent_settings["role"], height=100)
    career_task = st.text_area("Task Description", value=st.session_state.career_agent_settings["task"], height=100)
    career_output_format = st.text_area("Output Format", value=st.session_state.career_agent_settings["output_format"], height=150)
    
    # Add model selection dropdown for career planning agent
    career_model = st.selectbox(
        "Select Career Planning Assistant Model", 
        options=list(AVAILABLE_MODELS.keys()),
        format_func=lambda x: AVAILABLE_MODELS[x],
        index=list(AVAILABLE_MODELS.keys()).index(st.session_state.career_agent_settings["model"])
    )
    
    st.subheader("Report Submission Assistant Settings")
    submission_role = st.text_area("Character Setting", value=st.session_state.submission_agent_settings["role"], height=100)
    submission_task = st.text_area("Task Description", value=st.session_state.submission_agent_settings["task"], height=100)
    submission_output_format = st.text_area("Output Format", value=st.session_state.submission_agent_settings["output_format"], height=150)
    
    # Add model selection dropdown for submission agent
    submission_model = st.selectbox(
        "Select Report Submission Assistant Model", 
        options=list(AVAILABLE_MODELS.keys()),
        format_func=lambda x: AVAILABLE_MODELS[x],
        index=list(AVAILABLE_MODELS.keys()).index(st.session_state.submission_agent_settings["model"])
    )
    
    if st.button("Save Settings"):
        st.session_state.career_agent_settings = {
            "role": career_role,
            "task": career_task,
            "output_format": career_output_format,
            "model": career_model
        }
        
        st.session_state.submission_agent_settings = {
            "role": submission_role,
            "task": submission_task,
            "output_format": submission_output_format,
            "model": submission_model
        }
        
        st.success("Settings saved successfully")

# Tab 3: API Status
with tab3:
    st.header("API Status")
    
    col1, col2 = st.columns(2)
    
    with col1:
        status = "âœ… å·²è¿æ¥" if st.session_state.api_status["openrouter"] else "âŒ æœªè¿æ¥"
        st.metric("OpenRouter API", status)
        
        if not st.session_state.api_status["openrouter"]:
            st.warning("è¯·æ£€æŸ¥Streamlit Secretsä¸­çš„OPENROUTER_API_KEYæ˜¯å¦æ­£ç¡®è®¾ç½®")
    
    with col2:
        status = "âœ… å·²è¿æ¥" if st.session_state.api_status["langsmith"] else "âŒ æœªè¿æ¥"
        st.metric("LangSmith", status)
        
        if not st.session_state.api_status["langsmith"]:
            st.warning("è¯·æ£€æŸ¥Streamlit Secretsä¸­çš„LANGSMITH_API_KEYæ˜¯å¦æ­£ç¡®è®¾ç½®")
    
    # æ·»åŠ LangSmithè®¾ç½®ä¿¡æ¯
    if st.session_state.api_status["langsmith"]:
        st.subheader("LangSmithé…ç½®")
        st.code(f"""
é¡¹ç›®åç§°: {os.environ.get('LANGCHAIN_PROJECT', 'æœªè®¾ç½®')}
ç«¯ç‚¹: {os.environ.get('LANGCHAIN_ENDPOINT', 'æœªè®¾ç½®')}
è¿½è¸ªçŠ¶æ€: {'å¯ç”¨' if os.environ.get('LANGCHAIN_TRACING_V2') == 'true' else 'æœªå¯ç”¨'}
        """)
    
    # Add a refresh button for API status
    if st.button("åˆ·æ–°çŠ¶æ€"):
        with st.spinner("æ­£åœ¨æ£€æŸ¥APIçŠ¶æ€..."):
            check_api_status()
        st.rerun() 