import streamlit as st
import os
from PIL import Image
import io
import pandas as pd
import base64
from dotenv import load_dotenv
import requests
import json
from langchain.agents import AgentExecutor, create_react_agent
from langchain_core.tools import Tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langsmith import Client
from langsmith.run_helpers import traceable
import tempfile
import streamlit.components.v1 as components
import datetime
from io import BytesIO

# åˆå§‹åŒ–å…¨å±€å˜é‡ç”¨äºè®°å½•æ¨¡å‹ä¿¡æ¯
_run_metadata = {}

# Load environment variables
load_dotenv()

# Page configuration
st.set_page_config(
    page_title="Career Planning Assistant",
    page_icon="ğŸš€",
    layout="wide"
)

# Function to check API status - ç§»åŠ¨åˆ°æ–‡ä»¶å‰é¢
def check_api_status():
    # Check OpenRouter API
    try:
        openrouter_key = st.secrets.get("OPENROUTER_API_KEY")
        if openrouter_key:
            headers = {
                "Authorization": f"Bearer {openrouter_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://career-planner.streamlit.app"
            }
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json={
                    "model": "qwen/qwen-max",  # Use a default model
                    "messages": [{"role": "user", "content": "Hello"}],
                    "max_tokens": 5
                }
            )
            st.session_state.api_status["openrouter"] = response.status_code == 200
        else:
            st.session_state.api_status["openrouter"] = False
    except Exception as e:
        st.error(f"OpenRouter API error: {str(e)}")
        st.session_state.api_status["openrouter"] = False
    
    # Check LangSmith status
    try:
        langsmith_key = st.secrets.get("LANGSMITH_API_KEY")
        if langsmith_key:
            # ç¡®ä¿ç¯å¢ƒå˜é‡è®¾ç½®æ­£ç¡®
            os.environ["LANGSMITH_API_KEY"] = langsmith_key
            os.environ["LANGCHAIN_PROJECT"] = st.secrets.get("LANGSMITH_PROJECT", "career-planner")
            os.environ["LANGCHAIN_TRACING_V2"] = "true"
            os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"  # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ç«¯ç‚¹
            
            # åˆ›å»ºå®¢æˆ·ç«¯å¹¶æµ‹è¯•è¿æ¥ (ä»…åœ¨APIçŠ¶æ€é¡µé¢æ˜¾ç¤ºæ¶ˆæ¯)
            client = Client(api_key=langsmith_key)
            
            # ç®€å•åœ°ä½¿ç”¨APIè°ƒç”¨æ¥éªŒè¯è¿æ¥
            try:
                # ä½¿ç”¨Clientçš„list_projectsæ–¹æ³•æ£€æŸ¥è¿æ¥
                projects = client.list_projects(limit=1)
                st.session_state.api_status["langsmith"] = True
                # ä¸æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯ï¼Œåªåœ¨APIçŠ¶æ€é¡µé¢æ˜¾ç¤º
            except Exception as inner_e:
                st.error(f"LangSmith APIè¿æ¥æµ‹è¯•å¤±è´¥: {str(inner_e)}")
                st.session_state.api_status["langsmith"] = False
        else:
            st.session_state.api_status["langsmith"] = False
            st.warning("LangSmith APIå¯†é’¥æœªè®¾ç½®")
    except Exception as e:
        st.error(f"LangSmith API error: {str(e)}")
        st.session_state.api_status["langsmith"] = False

# æ·»åŠ ä¸€ä¸ªä¿®æ”¹åçš„call_openrouterå‡½æ•°ï¼ŒåŒ…å«æ¨¡å‹ä¿¡æ¯çš„è¿½è¸ª
@traceable(run_type="llm", name="OpenRouter AIè°ƒç”¨")
def call_openrouter(messages, model, temperature=0.7, is_vision=False, run_name="openrouter_call"):
    """è°ƒç”¨OpenRouter APIè·å–LLMå“åº”"""
    # è¿™ä¸ªç‰¹æ®Šå˜é‡æ˜¯ä¸ºäº†LangSmithè¿½è¸ªå…ƒæ•°æ®
    global _run_metadata
    
    # è®¾ç½®å…ƒæ•°æ®å­—å…¸ä»¥åœ¨LangSmithä¸­ä½¿ç”¨
    _run_metadata = {
        "model_name": model,
        "temperature": str(temperature), 
        "is_vision": str(is_vision),
        "messages_count": str(len(messages)),
        "model_provider": "OpenRouter"
    }
    
    try:
        api_key = st.secrets.get("OPENROUTER_API_KEY")
        if not api_key:
            return "Error: OpenRouter API key not set"
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://career-planner.streamlit.app"
        }
        
        # åˆ›å»ºJSONå®‰å…¨çš„æ¶ˆæ¯å¤åˆ¶ç‰ˆæœ¬
        safe_messages = []
        for msg in messages:
            safe_msg = {}
            for key, value in msg.items():
                if isinstance(value, str):
                    # ä»…å¤åˆ¶å­—ç¬¦ä¸²å€¼ï¼Œä¸åšç‰¹æ®Šå¤„ç†
                    safe_msg[key] = value
                else:
                    # éå­—ç¬¦ä¸²å€¼ç›´æ¥å¤åˆ¶
                    safe_msg[key] = value
            safe_messages.append(safe_msg)
        
        payload = {
            "model": model,
            "messages": safe_messages,
            "temperature": temperature
        }
        
        # For vision models, we might need additional parameters
        if is_vision:
            # Additional vision-specific settings if needed
            pass
        
        print(f"è°ƒç”¨OpenRouter API - æ¨¡å‹: {model}, æ¸©åº¦: {temperature}")
        
        # å‘é€APIè¯·æ±‚
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=payload
        )
        
        result = response.json()
        
        # å¦‚æœæœ‰æ¨¡å‹ä¿¡æ¯ï¼Œæ·»åŠ åˆ°å…ƒæ•°æ®
        if "model" in result:
            _run_metadata["actual_model"] = result["model"]
            print(f"å®é™…ä½¿ç”¨çš„æ¨¡å‹: {result['model']}")
        
        # æå–å“åº”å†…å®¹
        if "choices" in result and len(result["choices"]) > 0:
            return result["choices"][0]["message"]["content"]
        else:
            error_msg = f"Request failed: {str(result)}"
            print(error_msg)
            return error_msg
    except Exception as e:
        error_msg = f"Error during request: {str(e)}"
        print(error_msg)
        return error_msg

# Initialize LangSmith client
def init_langsmith():
    """Initialize LangSmith client from secrets."""
    try:
        langsmith_api_key = st.secrets.get("LANGSMITH_API_KEY", "")
        langsmith_project = st.secrets.get("LANGSMITH_PROJECT", "career-planner")
        
        if langsmith_api_key:
            os.environ["LANGCHAIN_API_KEY"] = langsmith_api_key  # å…¼å®¹æ—§ç‰ˆæœ¬
            os.environ["LANGSMITH_API_KEY"] = langsmith_api_key
            os.environ["LANGCHAIN_PROJECT"] = langsmith_project
            os.environ["LANGCHAIN_TRACING_V2"] = "true"
            
            # å¯ç”¨è¯¦ç»†æ—¥å¿—è®°å½•
            os.environ["LANGCHAIN_VERBOSE"] = "true"
            
            # ç¡®ä¿è®°å½•æ‰€æœ‰å­—æ®µ
            os.environ["LANGCHAIN_HIDE_INPUTS"] = "false"
            os.environ["LANGCHAIN_HIDE_MODEL_INFO"] = "false"
            
            print("LangSmith é…ç½®å®Œæˆï¼Œå·²å¯ç”¨è¯¦ç»†è·Ÿè¸ª")
            
            return True
        return False
    except Exception as e:
        st.error(f"Error initializing LangSmith: {str(e)}")
        return False

# åˆå§‹åŒ–LangSmith
langsmith_enabled = init_langsmith()

# Available models with full names
AVAILABLE_MODELS = {
    "qwen/qwen-max": "Qwen Max",
    "qwen/qwen3-32b:free": "Qwen 3 32B",
    "deepseek/deepseek-chat-v3-0324:free": "DeepSeek Chat v3"
}

# Session state initialization
if 'user_inputs' not in st.session_state:
    st.session_state.user_inputs = {
        "university": "",
        "major": "",
        "target_industry": "",
        "target_position": "",
        "transcript_text": ""
    }

if 'career_agent_settings' not in st.session_state:
    st.session_state.career_agent_settings = {
        "role": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„èŒä¸šè§„åˆ’é¡¾é—®ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„è¡Œä¸šçŸ¥è¯†å’Œè§è§£ã€‚",
        "task": "åŸºäºç”¨æˆ·çš„å­¦æœ¯èƒŒæ™¯ã€ä¸“ä¸šã€æœŸæœ›è¿›å…¥çš„è¡Œä¸šå’ŒèŒä½ï¼Œåˆ†æä»–ä»¬çš„èŒä¸šå‘å±•è·¯å¾„ï¼Œå¹¶æä¾›å…·ä½“ã€å¯è¡Œçš„å»ºè®®ã€‚",
        "output_format": "è¯·æä¾›ç»“æ„åŒ–çš„èŒä¸šè§„åˆ’åˆ†æï¼ŒåŒ…æ‹¬ï¼š\n1. èƒŒæ™¯åˆ†æ\n2. èŒä¸šè·¯å¾„å»ºè®®\n3. æŠ€èƒ½å‘å±•æ–¹å‘\n4. è¡Œä¸šå‰æ™¯\n5. çŸ­æœŸå’Œé•¿æœŸç›®æ ‡",
        "model": "qwen/qwen-max"
    }

if 'submission_agent_settings' not in st.session_state:
    st.session_state.submission_agent_settings = {
        "role": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„èŒä¸šè§„åˆ’æŠ¥å‘Šç¼–è¾‘ï¼Œæ“…é•¿æ•´åˆä¿¡æ¯å¹¶åˆ›å»ºè§†è§‰å¸å¼•åŠ›å¼ºçš„æŠ¥å‘Šã€‚",
        "task": "åŸºäºèŒä¸šè§„åˆ’è‰ç¨¿ï¼Œè¡¥å……ç›¸å…³è¡Œä¸šæ•°æ®å’Œä¿¡æ¯ï¼Œåˆ›å»ºä¸€ä»½åŒ…å«æ–‡å­—æè¿°å’Œå¯è§†åŒ–å†…å®¹çš„å®Œæ•´æŠ¥å‘Šã€‚",
        "output_format": "è¯·æä¾›ä¸“ä¸šçš„èŒä¸šè§„åˆ’æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š\n1. æ‰§è¡Œæ‘˜è¦\n2. è¯¦ç»†åˆ†æ\n3. æ•°æ®æ”¯æŒå›¾è¡¨\n4. è¡ŒåŠ¨è®¡åˆ’\n5. èµ„æºå»ºè®®",
        "model": "qwen/qwen-max"
    }

if 'draft_report' not in st.session_state:
    st.session_state.draft_report = ""

if 'final_report' not in st.session_state:
    st.session_state.final_report = ""

if 'api_status' not in st.session_state:
    st.session_state.api_status = {
        "openrouter": False,
        "langsmith": False
    }

# Simulated knowledge database
class KnowledgeDatabase:
    def __init__(self):
        # Load data from CSV file
        try:
            print(f"å°è¯•åŠ è½½CSVçŸ¥è¯†åº“: æ¨¡æ‹Ÿæ•°æ®åº“.csv")
            self.df = pd.read_csv("æ¨¡æ‹Ÿæ•°æ®åº“.csv")
            print(f"æˆåŠŸåŠ è½½CSVï¼Œå…±æœ‰{len(self.df)}è¡Œæ•°æ®")
            self.industries = {}
            self.majors = {}
            
            # Process data from CSV
            for _, row in self.df.iterrows():
                industry = row["è¡Œä¸š"]
                position = row["å²—ä½"]
                skill_group = row["æŠ€èƒ½ç»„"]
                skill_meaning = row["æŠ€èƒ½ç»„æ„ä¹‰"]
                knowledge_l1 = row["çŸ¥è¯†æ ‘-1çº§"]
                knowledge_l2 = row["çŸ¥è¯†æ ‘-2çº§"]
                
                # Create or get industry
                if industry not in self.industries:
                    self.industries[industry] = {
                        "positions": [],
                        "overview": f"{industry}è¡Œä¸šéœ€è¦å„ç§ä¸“ä¸šæŠ€èƒ½ï¼Œæä¾›å¤šç§èŒä¸šå‘å±•è·¯å¾„ã€‚"
                    }
                
                # Check if position already exists
                position_exists = False
                for pos in self.industries[industry]["positions"]:
                    if pos["name"] == position:
                        position_exists = True
                        # Update skills if not already included
                        if skill_group not in pos["skills"]:
                            pos["skills"] += f", {skill_group}"
                        break
                
                # Add new position if not exists
                if not position_exists:
                    self.industries[industry]["positions"].append({
                        "name": position,
                        "skills": skill_group,
                        "knowledge": f"{knowledge_l1}: {knowledge_l2}",
                        "education": "ç›¸å…³é¢†åŸŸçš„å­¦å£«åŠä»¥ä¸Šå­¦ä½",
                        "skill_description": skill_meaning,
                        "prospects": "è¡Œä¸šéœ€æ±‚ç¨³å®šï¼Œä¸“ä¸šå‘å±•å‰æ™¯è‰¯å¥½",
                        "salary": "æ ¹æ®ç»éªŒå’ŒæŠ€èƒ½æ°´å¹³ï¼Œè–ªèµ„èŒƒå›´ä¼šæœ‰æ‰€ä¸åŒ"
                    })
            
            # Create major data based on industry connections
            unique_knowledge = set(self.df["çŸ¥è¯†æ ‘-1çº§"].unique())
            for knowledge in unique_knowledge:
                relevant_rows = self.df[self.df["çŸ¥è¯†æ ‘-1çº§"] == knowledge]
                relevant_industries = relevant_rows["è¡Œä¸š"].unique()
                relevant_positions = relevant_rows["å²—ä½"].unique()
                
                self.majors[knowledge] = {
                    "suitable_industries": list(relevant_industries),
                    "suitable_positions": list(relevant_positions),
                    "core_skills": ", ".join(relevant_rows["æŠ€èƒ½ç»„"].unique()),
                    "career_paths": f"å¯ä»åˆçº§èŒä½å‘å±•åˆ°é«˜çº§èŒä½ï¼Œå¦‚{', '.join(relevant_positions[:3]) if len(relevant_positions) >= 3 else ', '.join(relevant_positions)}"
                }
                
            print(f"çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆ: {len(self.industries)}ä¸ªè¡Œä¸š, {len(self.majors)}ä¸ªä¸“ä¸šé¢†åŸŸ")
            for industry in self.industries.keys():
                print(f"  - è¡Œä¸š: {industry}, èŒä½æ•°: {len(self.industries[industry]['positions'])}")
            for major in list(self.majors.keys())[:5]:  # ä»…æ˜¾ç¤ºå‰5ä¸ªä¸“ä¸š
                print(f"  - ä¸“ä¸šé¢†åŸŸ: {major}")
                
        except Exception as e:
            print(f"åŠ è½½CSVæ•°æ®å¤±è´¥: {str(e)}")
            # Fallback to demo data
            self.initialize_demo_data()
    
    def initialize_demo_data(self):
        # This demo data is used as fallback if CSV loading fails
        self.industries = {
            "IT/Internet": {
                "positions": [
                    {
                        "name": "Software Engineer",
                        "skills": "Python, Java, JavaScript, Data Structures, Algorithms",
                        "education": "Bachelor's degree or above in Computer Science/Software Engineering",
                        "salary": "$80K-$150K",
                        "prospects": "Continuous industry demand, broad development space"
                    },
                    {
                        "name": "Frontend Developer",
                        "skills": "HTML, CSS, JavaScript, React/Vue/Angular, TypeScript",
                        "education": "Bachelor's degree or above in Computer Science related majors",
                        "salary": "$70K-$130K",
                        "prospects": "High demand with continuous internet product development"
                    },
                    {
                        "name": "Data Analyst",
                        "skills": "SQL, Python, R, Excel, Data Visualization, Statistics",
                        "education": "Bachelor's degree or above in Statistics/Mathematics/Computer Science",
                        "salary": "$75K-$140K",
                        "prospects": "Scarce talent in the big data era, good development prospects"
                    }
                ],
                "overview": "The IT/Internet industry has fast technology updates and fierce competition, but offers high salary levels and development space"
            },
            "Finance": {
                "positions": [
                    {
                        "name": "Investment Analyst",
                        "skills": "Financial Analysis, Valuation Models, Excel, Financial Market Knowledge",
                        "education": "Bachelor's degree or above in Finance/Economics/Accounting",
                        "salary": "$85K-$150K",
                        "prospects": "Stable financial industry with clear promotion paths"
                    },
                    {
                        "name": "Risk Control",
                        "skills": "Risk Assessment, Data Analysis, Regulatory Knowledge, Financial Instruments",
                        "education": "Bachelor's degree or above in Finance/Mathematics/Statistics",
                        "salary": "$90K-$160K",
                        "prospects": "Stable demand for risk control talent, good career development prospects"
                    }
                ],
                "overview": "The financial industry is relatively stable, emphasizing professionalism and compliance, with a mature career development system"
            }
        }
        
        self.majors = {
            "Computer Science": {
                "suitable_industries": ["IT/Internet", "Finance", "Education"],
                "suitable_positions": ["Software Engineer", "Data Analyst", "IT Consultant"],
                "core_skills": "Programming Languages, Data Structures, Algorithms, Databases, Network Fundamentals",
                "career_paths": "Can develop from Developer to Architect, Technical Manager, or Product Manager"
            },
            "Finance": {
                "suitable_industries": ["Finance", "Consulting", "Corporate Finance"],
                "suitable_positions": ["Investment Analyst", "Risk Control", "Financial Advisor"],
                "core_skills": "Financial Analysis, Financial Markets, Risk Management, Investment Theory",
                "career_paths": "Can develop from Analyst to Investment Manager, Risk Manager, or CFO"
            }
        }
    
    def query(self, query_type, query_value):
        """
        Query the database with different query types
        query_type can be: 'industry', 'position', 'major'
        """
        if query_type == 'industry' and query_value in self.industries:
            return self.industries[query_value]
        elif query_type == 'major' and query_value in self.majors:
            return self.majors[query_value]
        elif query_type == 'position':
            # Search for position across all industries
            for industry, industry_data in self.industries.items():
                for position in industry_data['positions']:
                    if position['name'] == query_value:
                        return position
            return None
        else:
            return None

# Initialize knowledge database
knowledge_db = KnowledgeDatabase()

# Function to analyze transcript with vision model through OpenRouter
def analyze_transcript_with_vision_model(image_bytes):
    try:
        api_key = st.secrets.get("OPENROUTER_API_KEY")
        if not api_key:
            return "Error: OpenRouter API key not set"
        
        # Convert image to base64
        base64_image = base64.b64encode(image_bytes).decode('utf-8')
        
        # Create message with image
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "This is a transcript. Please identify and extract all course names, credits, and grade information, and organize them into a table format."},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                ]
            }
        ]
        
        # Use Qwen's vision model through OpenRouter
        return call_openrouter(messages, "qwen/qwen2.5-vl-72b-instruct", temperature=0.3, is_vision=True)
    except Exception as e:
        return f"Error during analysis: {str(e)}"

# Function to render Mermaid diagrams
def render_mermaid(mermaid_code):
    # æ¸…ç†å¯èƒ½åŒ…å«çš„ç©ºæ ¼æˆ–ç‰¹æ®Šå­—ç¬¦
    mermaid_code = mermaid_code.strip()
    
    html = f"""
    <div class="mermaid">
    {mermaid_code}
    </div>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({{ 
            startOnLoad: true,
            theme: 'default',
            securityLevel: 'loose',
            logLevel: 'error'
        }});
    </script>
    """
    components.html(html, height=500)

# Function to query knowledge database
@traceable(run_type="chain", name="çŸ¥è¯†åº“æŸ¥è¯¢")
def query_knowledge_db(user_inputs):
    # åˆ›å»ºå…ƒæ•°æ®å­—å…¸
    run_metadata = {
        "query_type": "knowledge_db",
        "major": user_inputs['major'],
        "target_industry": user_inputs['target_industry'],
        "target_position": user_inputs['target_position']
    }
    
    print(f"æŸ¥è¯¢çŸ¥è¯†åº“: ä¸“ä¸š={user_inputs['major']}, è¡Œä¸š={user_inputs['target_industry']}, èŒä½={user_inputs['target_position']}")
    results = []
    
    # Query by industry
    if user_inputs['target_industry']:
        industry_data = knowledge_db.query('industry', user_inputs['target_industry'])
        if industry_data:
            print(f"æ‰¾åˆ°è¡Œä¸šä¿¡æ¯: {user_inputs['target_industry']}, åŒ…å«{len(industry_data['positions'])}ä¸ªèŒä½")
            results.append(f"è¡Œä¸šæ¦‚è§ˆ - {user_inputs['target_industry']}:\n{industry_data['overview']}")
            
            # If position is specified, find specific position data
            if user_inputs['target_position']:
                found = False
                for position in industry_data['positions']:
                    if position['name'] == user_inputs['target_position']:
                        found = True
                        print(f"æ‰¾åˆ°èŒä½ä¿¡æ¯: {position['name']}, æŠ€èƒ½: {position['skills']}")
                        # Check if we have new fields in our updated model
                        if 'skill_description' in position:
                            results.append(f"èŒä½è¯¦æƒ… - {position['name']}:\n"
                                          f"æ‰€éœ€æŠ€èƒ½: {position['skills']}\n"
                                          f"æŠ€èƒ½è¯¦ç»†æè¿°: {position.get('skill_description', 'æ— ç›¸å…³æè¿°')}\n"
                                          f"ç›¸å…³çŸ¥è¯†é¢†åŸŸ: {position.get('knowledge', 'æ— ç‰¹å®šçŸ¥è¯†é¢†åŸŸ')}\n"
                                          f"æ•™è‚²è¦æ±‚: {position['education']}\n"
                                          f"è–ªèµ„èŒƒå›´: {position['salary']}\n"
                                          f"èŒä¸šå‰æ™¯: {position['prospects']}")
                        else:
                            results.append(f"èŒä½è¯¦æƒ… - {position['name']}:\n"
                                          f"æ‰€éœ€æŠ€èƒ½: {position['skills']}\n"
                                          f"æ•™è‚²è¦æ±‚: {position['education']}\n"
                                          f"è–ªèµ„èŒƒå›´: {position['salary']}\n"
                                          f"èŒä¸šå‰æ™¯: {position['prospects']}")
                        break
                
                if not found:
                    print(f"æœªæ‰¾åˆ°èŒä½: {user_inputs['target_position']}")
                    results.append(f"åœ¨{user_inputs['target_industry']}è¡Œä¸šä¸­æœªæ‰¾åˆ°{user_inputs['target_position']}èŒä½çš„è¯¦ç»†ä¿¡æ¯ã€‚")
                    # List similar positions as alternatives
                    results.append(f"{user_inputs['target_industry']}è¡Œä¸šä¸­çš„å…¶ä»–èŒä½:")
                    for position in industry_data['positions']:
                        results.append(f"- {position['name']}: {position.get('skills', 'æ— æŠ€èƒ½ä¿¡æ¯')}")
            else:
                # List all positions in this industry
                results.append(f"{user_inputs['target_industry']}è¡Œä¸šä¸­çš„çƒ­é—¨èŒä½:")
                for position in industry_data['positions']:
                    skills_summary = position['skills'].split(',')[0:3] if ',' in position['skills'] else [position['skills']]
                    skills_text = ', '.join(skills_summary)
                    results.append(f"- {position['name']}: æŠ€èƒ½è¦æ±‚({skills_text}), {position['prospects']}")
    
    # Query by major
    if user_inputs['major']:
        major_data = knowledge_db.query('major', user_inputs['major'])
        if major_data:
            print(f"æ‰¾åˆ°ä¸“ä¸šä¿¡æ¯: {user_inputs['major']}, é€‚åˆè¡Œä¸š: {major_data['suitable_industries']}")
            results.append(f"{user_inputs['major']}ä¸“ä¸šçš„èŒä¸šæ–¹å‘:\n"
                          f"é€‚åˆçš„è¡Œä¸š: {', '.join(major_data['suitable_industries'])}\n"
                          f"é€‚åˆçš„èŒä½: {', '.join(major_data['suitable_positions'])}\n"
                          f"æ ¸å¿ƒæŠ€èƒ½: {major_data['core_skills']}\n"
                          f"èŒä¸šå‘å±•è·¯å¾„: {major_data['career_paths']}")
        else:
            print(f"æœªæ‰¾åˆ°ä¸“ä¸šçš„ç²¾ç¡®åŒ¹é…: {user_inputs['major']}, å°è¯•æ¨¡ç³ŠåŒ¹é…")
            # Try fuzzy match with knowledge areas
            found = False
            for major_name, major_info in knowledge_db.majors.items():
                if user_inputs['major'] in major_name or major_name in user_inputs['major']:
                    print(f"æ‰¾åˆ°ç›¸å…³ä¸“ä¸š: {major_name}")
                    results.append(f"æœªæ‰¾åˆ°å®Œå…¨åŒ¹é…çš„ä¸“ä¸šï¼Œä½†æ‰¾åˆ°ç›¸å…³ä¸“ä¸š {major_name}:\n"
                                 f"é€‚åˆçš„è¡Œä¸š: {', '.join(major_info['suitable_industries'])}\n"
                                 f"é€‚åˆçš„èŒä½: {', '.join(major_info['suitable_positions'])}\n"
                                 f"æ ¸å¿ƒæŠ€èƒ½: {major_info['core_skills']}\n"
                                 f"èŒä¸šå‘å±•è·¯å¾„: {major_info['career_paths']}")
                    found = True
                    break
            
            if not found:
                results.append(f"æœªæ‰¾åˆ°ä¸{user_inputs['major']}ä¸“ä¸šç›´æ¥ç›¸å…³çš„ä¿¡æ¯ã€‚å»ºè®®è€ƒè™‘ä»¥ä¸‹çŸ¥è¯†é¢†åŸŸ:")
                for major_name in list(knowledge_db.majors.keys())[:5]:  # List top 5 available majors
                    results.append(f"- {major_name}")
    
    # Query by position (if not already found)
    if user_inputs['target_position'] and not user_inputs['target_industry']:
        position_found = False
        for industry, industry_data in knowledge_db.industries.items():
            for position in industry_data['positions']:
                if position['name'] == user_inputs['target_position']:
                    position_found = True
                    print(f"æ‰¾åˆ°èŒä½ä¿¡æ¯(ä¸æŒ‡å®šè¡Œä¸š): {position['name']} in {industry}")
                    results.append(f"èŒä½è¯¦æƒ… - {position['name']} (åœ¨{industry}è¡Œä¸šä¸­):\n"
                                  f"æ‰€éœ€æŠ€èƒ½: {position['skills']}\n"
                                  f"æŠ€èƒ½è¯¦ç»†æè¿°: {position.get('skill_description', 'æ— ç›¸å…³æè¿°')}\n"
                                  f"ç›¸å…³çŸ¥è¯†é¢†åŸŸ: {position.get('knowledge', 'æ— ç‰¹å®šçŸ¥è¯†é¢†åŸŸ')}\n"
                                  f"æ•™è‚²è¦æ±‚: {position['education']}\n"
                                  f"è–ªèµ„èŒƒå›´: {position['salary']}\n"
                                  f"èŒä¸šå‰æ™¯: {position['prospects']}")
                    break
            if position_found:
                break
        
        if not position_found:
            print(f"æœªæ‰¾åˆ°èŒä½(ä¸æŒ‡å®šè¡Œä¸š): {user_inputs['target_position']}")
            results.append(f"æœªæ‰¾åˆ°{user_inputs['target_position']}èŒä½çš„è¯¦ç»†ä¿¡æ¯ã€‚")
            # Try to suggest similar positions
            similar_positions = []
            for industry, industry_data in knowledge_db.industries.items():
                for position in industry_data['positions']:
                    if user_inputs['target_position'] in position['name'] or position['name'] in user_inputs['target_position']:
                        similar_positions.append((position['name'], industry))
            
            if similar_positions:
                results.append("å¯èƒ½ç›¸å…³çš„èŒä½:")
                for pos, ind in similar_positions:
                    results.append(f"- {pos} (åœ¨{ind}è¡Œä¸š)")
    
    # If no specific queries matched, provide general industry overview
    if not results:
        print("æœªæ‰¾åˆ°ä»»ä½•ç›¸å…³ä¿¡æ¯ï¼Œæä¾›é€šç”¨æ¦‚è§ˆ")
        results.append("çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ä¸æ‚¨çš„æŸ¥è¯¢ç›´æ¥åŒ¹é…çš„ä¿¡æ¯ã€‚")
        results.append("å¯ç”¨çš„è¡Œä¸šä¿¡æ¯:")
        for industry in knowledge_db.industries.keys():
            results.append(f"- {industry}")
        
        results.append("\nå¯ç”¨çš„çŸ¥è¯†é¢†åŸŸ:")
        for major in knowledge_db.majors.keys():
            results.append(f"- {major}")
    
    response = "\n\n".join(results)
    print(f"çŸ¥è¯†åº“æŸ¥è¯¢å®Œæˆï¼Œè¿”å›{len(response)}å­—èŠ‚çš„ä¿¡æ¯")
    return response

# ä½¿ç”¨ @traceable è£…é¥°å™¨è¿½è¸ªç”ŸæˆèŒä¸šè§„åˆ’è‰ç¨¿çš„è¿‡ç¨‹
@traceable(run_type="chain", name="èŒä¸šè§„åˆ’è‰ç¨¿ç”Ÿæˆ")
def generate_career_planning_draft(user_inputs, agent_settings):
    """ä½¿ç”¨è¿½è¸ªè£…é¥°å™¨ç”ŸæˆèŒä¸šè§„åˆ’è‰ç¨¿"""
    # åˆ›å»ºå…ƒæ•°æ®å­—å…¸
    run_metadata = {
        "model": agent_settings["model"],
        "step": "draft_generation",
        "target_industry": user_inputs['target_industry'],
        "target_position": user_inputs['target_position']
    }
    
    try:
        # Query the knowledge database
        kb_data = query_knowledge_db(user_inputs)
        
        # Prepare the prompt for the career planning assistant
        role = agent_settings["role"]
        task = agent_settings["task"]
        output_format = agent_settings["output_format"]
        model = agent_settings["model"]
        
        # è®°å½•ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯
        print(f"èŒä¸šè§„åˆ’è‰ç¨¿ä½¿ç”¨æ¨¡å‹: {model}")
        
        user_info = f"""
        ç”¨æˆ·ä¿¡æ¯:
        - å¤§å­¦: {user_inputs['university']}
        - ä¸“ä¸š: {user_inputs['major']}
        - ç›®æ ‡è¡Œä¸š: {user_inputs['target_industry']}
        - ç›®æ ‡èŒä½: {user_inputs['target_position']}
        
        æˆç»©å•ä¿¡æ¯:
        {user_inputs['transcript_text']}
        
        çŸ¥è¯†åº“ä¿¡æ¯ (éå¸¸é‡è¦ï¼Œè¯·åŠ¡å¿…è¯¦ç»†å‚è€ƒè¿™äº›ä¿¡æ¯):
        {kb_data}
        """
        
        system_prompt = f"""{role}

{task}

è¯·åŠ¡å¿…è¯¦ç»†å‚è€ƒçŸ¥è¯†åº“ä¸­æä¾›çš„ä¿¡æ¯ï¼Œè¿™äº›æ˜¯çœŸå®çš„è¡Œä¸šå’ŒèŒä½æ•°æ®ï¼Œå¯¹èŒä¸šè§„åˆ’è‡³å…³é‡è¦ã€‚æ ¹æ®ç”¨æˆ·çš„ä¸“ä¸šã€ç›®æ ‡å’ŒçŸ¥è¯†åº“ä¿¡æ¯ï¼Œæä¾›æœ‰é’ˆå¯¹æ€§çš„èŒä¸šå»ºè®®ã€‚

è¾“å‡ºæ ¼å¼è¦æ±‚:
{output_format}
"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_info}
        ]
        
        # Make API call through OpenRouter
        response = call_openrouter(
            messages=messages, 
            model=model, 
            temperature=0.7,
            run_name="èŒä¸šè§„åˆ’AIè°ƒç”¨"
        )
        
        return response
    except Exception as e:
        error_msg = f"æŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        print(error_msg)
        return error_msg

# ä½¿ç”¨ @traceable è£…é¥°å™¨è¿½è¸ªç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šçš„è¿‡ç¨‹
@traceable(run_type="chain", name="æœ€ç»ˆèŒä¸šè§„åˆ’æŠ¥å‘Šç”Ÿæˆ")
def generate_final_report(draft_report, agent_settings):
    """ä½¿ç”¨è¿½è¸ªè£…é¥°å™¨ç”Ÿæˆæœ€ç»ˆèŒä¸šè§„åˆ’æŠ¥å‘Š"""
    # åˆ›å»ºå…ƒæ•°æ®å­—å…¸
    run_metadata = {
        "model": agent_settings["model"],
        "step": "final_report_generation",
        "draft_length": len(draft_report) if draft_report else 0
    }
    
    try:
        # Prepare the prompt for the submission agent
        role = agent_settings["role"]
        task = agent_settings["task"]
        output_format = agent_settings["output_format"]
        model = agent_settings["model"]
        
        # è®°å½•ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯
        print(f"æœ€ç»ˆæŠ¥å‘Šä½¿ç”¨æ¨¡å‹: {model}")
        
        # æ›´æ–°ç³»ç»Ÿæç¤ºï¼Œæä¾›æ›´ç®€å•çš„Mermaidå›¾è¡¨ç¤ºä¾‹å’Œæ›´ä¸¥æ ¼çš„è¯­æ³•è¦æ±‚
        system_prompt = f"""{role}

{task}

è¯·åŸºäºè‰ç¨¿ä¸­çš„æ•°æ®å’Œè¡Œä¸šä¿¡æ¯ï¼Œç¡®ä¿æœ€ç»ˆæŠ¥å‘Šè¯¦ç»†åæ˜ çŸ¥è¯†åº“ä¸­çš„ä¸“ä¸šæ•°æ®ã€‚è¿™äº›è¡Œä¸šå’ŒèŒä½ä¿¡æ¯æ˜¯çœŸå®çš„ï¼Œåº”è¯¥åœ¨æŠ¥å‘Šä¸­å¾—åˆ°å……åˆ†å±•ç¤ºã€‚

è¾“å‡ºæ ¼å¼è¦æ±‚:
{output_format}

è¯·åœ¨é€‚å½“çš„ä½ç½®åŒ…å«Mermaidå›¾è¡¨ã€‚åˆ›å»ºMermaidå›¾è¡¨æ—¶ï¼Œè¯·æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š
1. å°†å›¾è¡¨ä»£ç åŒ…è£¹åœ¨```mermaidå’Œ```æ ‡ç­¾ä¸­
2. ä½¿ç”¨éå¸¸ç®€å•çš„Mermaidè¯­æ³•ï¼Œé¿å…å¤æ‚çš„åŠŸèƒ½
3. åˆ›å»ºä¸€ä¸ªç®€å•çš„èŒä¸šè·¯å¾„æµç¨‹å›¾
4. å›¾è¡¨ä¸­åªä½¿ç”¨åŸºæœ¬èŠ‚ç‚¹å’Œè¿æ¥ï¼Œä¸è¦ä½¿ç”¨å¤æ‚æ ·å¼
5. é¿å…åœ¨èŠ‚ç‚¹æ–‡å­—ä¸­ä½¿ç”¨ç‰¹æ®Šå­—ç¬¦å’Œæ ‡ç‚¹ç¬¦å·
6. æ‰€æœ‰èŠ‚ç‚¹å¿…é¡»æœ‰è¿æ¥ï¼Œä¸èƒ½æœ‰å­¤ç«‹èŠ‚ç‚¹

éå¸¸ç®€å•çš„æœ‰æ•ˆMermaidä»£ç ç¤ºä¾‹ï¼š
```mermaid
flowchart TD
    A[å¼€å§‹] --> B[å­¦ä¹ ]
    B --> C[å·¥ä½œ]
```

æ³¨æ„ï¼šè¯·ç¡®ä¿ä½¿ç”¨æœ€ç®€å•çš„è¯­æ³•åˆ›å»ºå›¾è¡¨ï¼Œé¿å…ä»»ä½•å¯èƒ½å¯¼è‡´è¯­æ³•é”™è¯¯çš„å¤æ‚åŠŸèƒ½ã€‚
æ‰€æœ‰å†…å®¹è¯·ä½¿ç”¨ä¸­æ–‡è¾“å‡ºã€‚
"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"è¿™æ˜¯èŒä¸šè§„åˆ’æŠ¥å‘Šè‰ç¨¿ï¼š\n\n{draft_report}\n\nåŸºäºè¿™ä»½è‰ç¨¿ï¼Œè¯·è¡¥å……ç›¸å…³ä¿¡æ¯ï¼Œåˆ›å»ºä¸€ä»½åŒ…å«æ–‡å­—å’Œä¸€ä¸ªç®€å•æµç¨‹å›¾çš„å®Œæ•´æŠ¥å‘Šã€‚å›¾è¡¨å¿…é¡»éå¸¸ç®€å•ï¼Œä»…ä½¿ç”¨åŸºæœ¬èŠ‚ç‚¹å’Œè¿æ¥ã€‚è¯·ç”¨ä¸­æ–‡è¾“å‡ºæ‰€æœ‰å†…å®¹ã€‚"}
        ]
        
        # Make API call through OpenRouter
        response = call_openrouter(
            messages=messages, 
            model=model, 
            temperature=0.7,
            run_name="æŠ¥å‘Šç”ŸæˆAIè°ƒç”¨"
        )
        
        return response
    except Exception as e:
        error_msg = f"æŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        print(error_msg)
        return error_msg

# Check API status on startup
check_api_status()

# Main application interface
st.title("Career Planning Assistant")

# Create tabs
tab1, tab2, tab3 = st.tabs(["Information Collection", "Agent Settings", "API Status"])

# Tab 1: Information Collection
with tab1:
    st.header("User Information Collection")
    
    col1, col2 = st.columns(2)
    
    with col1:
        university = st.text_input("University", value=st.session_state.user_inputs["university"])
        major = st.text_input("Major", value=st.session_state.user_inputs["major"])
    
    with col2:
        target_industry = st.text_input("Target Industry", value=st.session_state.user_inputs["target_industry"])
        target_position = st.text_input("Target Position", value=st.session_state.user_inputs["target_position"])
    
    # Transcript upload
    uploaded_file = st.file_uploader("Upload Transcript (Image formats only)", type=['png', 'jpg', 'jpeg'])
    
    transcript_text = ""
    if uploaded_file is not None:
        # Read the file
        image_bytes = uploaded_file.getvalue()
        
        # Call vision model to analyze the transcript
        with st.spinner("Analyzing transcript..."):
            transcript_text = analyze_transcript_with_vision_model(image_bytes)
        
        # Display the analysis result in an expandable section
        with st.expander("Transcript Analysis Result", expanded=True):
            st.write(transcript_text)
    
    # Store user inputs in session state
    if st.button("Start Analysis"):
        # Validate inputs
        if not (major or target_industry or target_position):
            st.error("Error: At least one of Major, Target Industry, or Target Position must be filled")
        else:
            st.session_state.user_inputs = {
                "university": university,
                "major": major,
                "target_industry": target_industry,
                "target_position": target_position,
                "transcript_text": transcript_text
            }
            
            # Generate career planning draft
            with st.spinner("Generating career planning report draft..."):
                draft_report = generate_career_planning_draft(
                    st.session_state.user_inputs,
                    st.session_state.career_agent_settings
                )
                st.session_state.draft_report = draft_report
            
            # Display the draft report in a collapsible section
            with st.expander("Career Planning Report Draft", expanded=False):
                st.write(st.session_state.draft_report)
            
            # Generate final report
            with st.spinner("Generating final career planning report..."):
                final_report = generate_final_report(
                    st.session_state.draft_report,
                    st.session_state.submission_agent_settings
                )
                st.session_state.final_report = final_report
            
            # Display the final report
            st.subheader("Final Career Planning Report")
            
            # æ˜¾ç¤ºæŠ¥å‘Šå†…å®¹
            if st.session_state.final_report:
                # æ›´æ–°å¤„ç†å›¾è¡¨çš„æ–¹å¼ï¼Œæ·»åŠ æ›´å¤šå¥å£®æ€§
                try:
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«Mermaidå›¾è¡¨
                    if "```mermaid" in st.session_state.final_report:
                        # Process and display text and Mermaid diagrams separately
                        report_parts = st.session_state.final_report.split("```mermaid")
                        
                        # Display the first text part
                        if report_parts and len(report_parts) > 0:
                            st.write(report_parts[0])
                        
                        # Process each mermaid diagram and following text
                        for i in range(1, len(report_parts)):
                            part = report_parts[i]
                            # Split by the closing code block marker
                            if "```" in part:
                                mermaid_code, remaining_text = part.split("```", 1)
                                # Clean mermaid code and render
                                mermaid_code = mermaid_code.strip()
                                
                                # ä¸ºè°ƒè¯•æ·»åŠ ä¸€ä¸ªé€‰é¡¹æ¥æ˜¾ç¤ºåŸå§‹mermaidä»£ç 
                                with st.expander("æŸ¥çœ‹å›¾è¡¨ä»£ç "):
                                    st.code(mermaid_code, language="mermaid")
                                
                                # å°è¯•ä¿®å¤å¸¸è§çš„è¯­æ³•é”™è¯¯
                                if "graph" in mermaid_code and "flowchart" not in mermaid_code:
                                    # æ—§ç‰ˆè¯­æ³•ï¼Œè½¬æ¢ä¸ºæ–°ç‰ˆ
                                    mermaid_code = mermaid_code.replace("graph", "flowchart")
                                
                                try:
                                    # Render diagram with error handling
                                    render_mermaid(mermaid_code)
                                except Exception as e:
                                    st.error(f"å›¾è¡¨æ¸²æŸ“å¤±è´¥: {str(e)}")
                                    st.code(mermaid_code, language="mermaid")
                                    
                                    # å°è¯•æ¸²æŸ“ä¸€ä¸ªå¤‡ç”¨çš„ç®€å•å›¾è¡¨
                                    st.warning("å°è¯•æ¸²æŸ“å¤‡ç”¨å›¾è¡¨...")
                                    try:
                                        fallback_code = """
flowchart TD
    A[å­¦ä¹ ] --> B[å®è·µ]
    B --> C[å°±ä¸š]
                                        """
                                        render_mermaid(fallback_code)
                                    except:
                                        st.error("å¤‡ç”¨å›¾è¡¨ä¹Ÿæ¸²æŸ“å¤±è´¥")
                                
                                # Display the text that follows
                                st.write(remaining_text)
                            else:
                                # No closing marker found, just display as text
                                st.write(part)
                    else:
                        # å¦‚æœæ²¡æœ‰å›¾è¡¨æ ‡è®°ï¼Œç›´æ¥æ˜¾ç¤ºæŠ¥å‘Š
                        st.write(st.session_state.final_report)
                except Exception as e:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œç›´æ¥æ˜¾ç¤ºå®Œæ•´æŠ¥å‘Š
                    st.error(f"å¤„ç†å›¾è¡¨æ—¶å‡ºé”™: {str(e)}")
                    st.write(st.session_state.final_report)

# Tab 2: Agent Settings
with tab2:
    st.header("Agent Settings")
    
    st.subheader("Career Planning Assistant Settings")
    career_role = st.text_area("Character Setting", value=st.session_state.career_agent_settings["role"], height=100)
    career_task = st.text_area("Task Description", value=st.session_state.career_agent_settings["task"], height=100)
    career_output_format = st.text_area("Output Format", value=st.session_state.career_agent_settings["output_format"], height=150)
    
    # Add model selection dropdown for career planning agent
    career_model = st.selectbox(
        "Select Career Planning Assistant Model", 
        options=list(AVAILABLE_MODELS.keys()),
        format_func=lambda x: AVAILABLE_MODELS[x],
        index=list(AVAILABLE_MODELS.keys()).index(st.session_state.career_agent_settings["model"])
    )
    
    st.subheader("Report Submission Assistant Settings")
    submission_role = st.text_area("Character Setting", value=st.session_state.submission_agent_settings["role"], height=100)
    submission_task = st.text_area("Task Description", value=st.session_state.submission_agent_settings["task"], height=100)
    submission_output_format = st.text_area("Output Format", value=st.session_state.submission_agent_settings["output_format"], height=150)
    
    # Add model selection dropdown for submission agent
    submission_model = st.selectbox(
        "Select Report Submission Assistant Model", 
        options=list(AVAILABLE_MODELS.keys()),
        format_func=lambda x: AVAILABLE_MODELS[x],
        index=list(AVAILABLE_MODELS.keys()).index(st.session_state.submission_agent_settings["model"])
    )
    
    if st.button("Save Settings"):
        st.session_state.career_agent_settings = {
            "role": career_role,
            "task": career_task,
            "output_format": career_output_format,
            "model": career_model
        }
        
        st.session_state.submission_agent_settings = {
            "role": submission_role,
            "task": submission_task,
            "output_format": submission_output_format,
            "model": submission_model
        }
        
        st.success("Settings saved successfully")

# Tab 3: API Status
with tab3:
    st.header("API Status")
    
    col1, col2 = st.columns(2)
    
    with col1:
        status = "âœ… å·²è¿æ¥" if st.session_state.api_status["openrouter"] else "âŒ æœªè¿æ¥"
        st.metric("OpenRouter API", status)
        
        if not st.session_state.api_status["openrouter"]:
            st.warning("è¯·æ£€æŸ¥Streamlit Secretsä¸­çš„OPENROUTER_API_KEYæ˜¯å¦æ­£ç¡®è®¾ç½®")
    
    with col2:
        status = "âœ… å·²è¿æ¥" if st.session_state.api_status["langsmith"] else "âŒ æœªè¿æ¥"
        st.metric("LangSmith", status)
        
        if not st.session_state.api_status["langsmith"]:
            st.warning("è¯·æ£€æŸ¥Streamlit Secretsä¸­çš„LANGSMITH_API_KEYæ˜¯å¦æ­£ç¡®è®¾ç½®")
    
    # æ·»åŠ LangSmithè®¾ç½®ä¿¡æ¯
    if st.session_state.api_status["langsmith"]:
        st.subheader("LangSmithé…ç½®")
        st.code(f"""
é¡¹ç›®åç§°: {os.environ.get('LANGCHAIN_PROJECT', 'æœªè®¾ç½®')}
ç«¯ç‚¹: {os.environ.get('LANGCHAIN_ENDPOINT', 'æœªè®¾ç½®')}
è¿½è¸ªçŠ¶æ€: {'å¯ç”¨' if os.environ.get('LANGCHAIN_TRACING_V2') == 'true' else 'æœªå¯ç”¨'}
        """)
    
    # Add a refresh button for API status
    if st.button("åˆ·æ–°çŠ¶æ€"):
        with st.spinner("æ­£åœ¨æ£€æŸ¥APIçŠ¶æ€..."):
            check_api_status()
        st.rerun()